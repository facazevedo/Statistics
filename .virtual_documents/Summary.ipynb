


import numpy as np
from scipy.integrate import cumtrapz
import matplotlib.pyplot as plt
import pandas as pd
from itertools import product
import scipy.stats as stats
import matplotlib.patches as mpatches
from scipy.stats import norm, t, ttest_1samp
from math import ceil
from IPython.display import HTML
from matplotlib.ticker import FormatStrFormatter
from collections import Counter

def print_color(text, color="black", font_weight="normal", font_style="normal", font_size="small"): 
    display(HTML(f'<span style="color: {color};font-weight: {font_weight}; font-style: {font_style}; font-size: {font_size};">{text}</span>'))





lowest_height_whole_pop= 55
highest_height_whole_pop = 85
mean_height_whole_pop = 70
std_height_whole_pop = 3
num_bars_whole_pop = 100
n_points_x_axis = 1000

def normal_distribution(x, mu, sigma):
    pdf_values = (1 / (sigma * np.sqrt(2 * np.pi))) * np.exp(-0.5 * ((x - mu) / sigma) ** 2)
    return pdf_values

def create_whole_population(f_normal_distribution, lowest_height, highest_height, mean_height, std_height, n_points):
    x_values = np.linspace(lowest_height, highest_height, n_points)
    pdf_curve = [f_normal_distribution(x, mean_height, std_height) for x in x_values]
    return pd.DataFrame({'Height': x_values, 'Density': pdf_curve})

def plot_whole_population(df, num_bins, lowest_height, highest_height):
    fig, ax = plt.subplots(figsize=(4, 4))
    bin_width = (highest_height - lowest_height) / num_bins
    mid_x_values = np.linspace(lowest_height, highest_height, num_bins) + bin_width / 2
    pdf_values = [df['Density'].iloc[np.argmin(np.abs(df['Height'] - x))] for x in mid_x_values]
    ax.plot(df['Height'], df['Density'], label='PDF', color='red', linestyle='dashed', alpha=0.5, linewidth=1.5)
    ax.bar(mid_x_values, pdf_values, width=bin_width, alpha=0.5, edgecolor='black', linewidth=0.5, label='Histogram')
    ax.set_title('Whole Population of Human Heights')
    ax.set_xlabel('Height (inches)')
    ax.set_ylabel('Density')
    ax.legend()
    plt.tight_layout()
    plt.show()

# Create whole population
df_whole_pop = create_whole_population(normal_distribution, lowest_height_whole_pop, highest_height_whole_pop, 
                                       mean_height_whole_pop, std_height_whole_pop, n_points_x_axis)

# Plot whole population with histogram bars
plot_whole_population(df_whole_pop, num_bars_whole_pop, lowest_height_whole_pop, highest_height_whole_pop)





lowest_height_mini_pop_01= 55
mean_height_mini_pop_01 = 70
highest_height_mini_pop_01 = 85
std_height_mini_pop_01 = 3
num_bars_mini_pop_01 = 100
# approx_num_bars_mini_pop_01=9
# approx_total_count_mini_pop_01=30
approx_num_bars_mini_pop_01=9
approx_total_count_mini_pop_01=15

def create_mini_population(f_normal_distribution, start, end, n_bins, total_count, mean_height, std_height):
    bin_edges = np.linspace(start, end, n_bins + 1)
    bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2.0
    bin_centers = np.round(bin_centers, 2)  # Round bin_centers to two decimal places
    bin_width = (end - start) / n_bins
    densities = np.array([np.mean(f_normal_distribution(np.linspace(edge, bin_edges[i+1], 100), mean_height, std_height)) for i, edge in enumerate(bin_edges[:-1])])
    float_counts = densities * total_count / sum(densities)
    int_counts = np.round(float_counts).astype(int)
    non_zero_indices = int_counts != 0
    bin_centers = bin_centers[non_zero_indices]
    int_counts = int_counts[non_zero_indices]
    probabilities = int_counts / sum(int_counts)  # Calculate probabilities
    return pd.DataFrame({'Height': bin_centers, 'Count': int_counts, 'Probability': probabilities})

def plot_mini_population(df, ax, column_name="Height", label=None):
    centers = df[column_name]
    counts = df['Count']
    bin_width = min(np.diff(centers))
    ax.bar(centers, counts, width=bin_width, alpha=0.5, edgecolor='black', linewidth=0.5, label=label, align='edge')
 
def calculate_weighted_mean(df_col_value, df_col_count):
    weighted_mean = (df_col_value * df_col_count).sum() / df_col_count.sum()
    return weighted_mean

def calculate_weighted_std(df_col_value, df_col_count):
    weighted_mean = (df_col_value * df_col_count).sum() / df_col_count.sum()
    squared_deviations = ((df_col_value - weighted_mean) ** 2) * df_col_count
    weighted_variance = squared_deviations.sum() / df_col_count.sum()
    weighted_std = np.sqrt(weighted_variance)
    return weighted_std


# Create mini (discretized) population
df_mini_pop_01 = create_mini_population(normal_distribution, lowest_height_mini_pop_01, highest_height_mini_pop_01, 
                                        approx_num_bars_mini_pop_01, approx_total_count_mini_pop_01, mean_height_mini_pop_01, std_height_mini_pop_01)

# Display mini population
display(df_mini_pop_01)

# Plot mini population
fig, ax = plt.subplots(figsize=(4, 4))
plot_mini_population(df_mini_pop_01, ax, label="Population 1")
ax.set_title('Mini Population of Human Heights')
ax.set_xlabel('Height (inches)')
ax.set_ylabel('Count')
plt.tight_layout()
plt.show()

# Summary
mean_mini_pop_01 = calculate_weighted_mean(df_mini_pop_01['Height'], df_mini_pop_01['Count'])
std_mini_pop_01 = calculate_weighted_std(df_mini_pop_01['Height'], df_mini_pop_01['Count'])

print(f"Unique elements: {df_mini_pop_01['Height'].unique()}")
print(f"Total count of elements: {df_mini_pop_01['Count'].sum()}")
print(f"Mean: {mean_mini_pop_01}")
print(f"Std: {std_mini_pop_01:.2f}")





lowest_height_mini_pop_02= 75
mean_height_mini_pop_02 = 90
highest_height_mini_pop_02 = 105
std_height_mini_pop_02 = 3
num_bars_mini_pop_02 = 100
approx_num_bars_mini_pop_02=11
approx_total_count_mini_pop_02=15

def plot_two_mini_pops(df1, df2, sample_mean_mini_pop_1=None, sample_mean_mini_pop_2=None, label_pop_01="Population 1", label_pop_02="Population 2"):
    fig, ax = plt.subplots(figsize=(6, 6))
    # Plot the first mini population
    plot_mini_population(df1, ax, label=label_pop_01)
    # Plot the second mini population
    plot_mini_population(df2, ax, label=label_pop_02)
    # Plot the red dot for sample_mean_mini_pop_1 if provided
    if sample_mean_mini_pop_1 is not None:
        ax.scatter(sample_mean_mini_pop_1, 0, color='red', zorder=5)
    # Plot the red dot for sample_mean_mini_pop_2 if provided
    if sample_mean_mini_pop_2 is not None:
        ax.scatter(sample_mean_mini_pop_2, 0, color='red', zorder=5)
    ax.set_title('Mini Populations of Human Heights (Not realistic)')
    ax.set_xlabel('Height (inches)')
    ax.set_ylabel('Count')
    ax.legend()
    plt.tight_layout()
    plt.show()
    
# Create mini (discretized) population
df_mini_pop_02 = create_mini_population(normal_distribution, lowest_height_mini_pop_02, highest_height_mini_pop_02, 
                                        approx_num_bars_mini_pop_02, approx_total_count_mini_pop_02, mean_height_mini_pop_02, std_height_mini_pop_02)

# Summary
# Mini pop 01
mean_mini_pop_01 = calculate_weighted_mean(df_mini_pop_01['Height'], df_mini_pop_01['Count'])
std_mini_pop_01 = calculate_weighted_std(df_mini_pop_01['Height'], df_mini_pop_01['Count'])

print('Mini pop 01')
display(df_mini_pop_01)
#print(f"Unique elements: {df_mini_pop_01['Height'].unique()}")
print(f"Total count of elements: {df_mini_pop_01['Count'].sum()}")
print(f"Mean: {mean_mini_pop_01}")
print(f"Std: {std_mini_pop_01:.2f}")

print('')

# Mini pop 02
mean_mini_pop_02 = calculate_weighted_mean(df_mini_pop_02['Height'], df_mini_pop_02['Count'])
std_mini_pop_02 = calculate_weighted_std(df_mini_pop_02['Height'], df_mini_pop_02['Count'])

print('Mini pop 02')
display(df_mini_pop_02)
#print(f"Unique elements: {df_mini_pop_02['Height'].unique()}")
print(f"Total count of elements: {df_mini_pop_02['Count'].sum()}")
print(f"Mean: {mean_mini_pop_02}")
print(f"Std: {std_mini_pop_02:.2f}")

# Plot mini population
plot_two_mini_pops(df_mini_pop_01, df_mini_pop_02)





sample_size_mini_pop_01 = 6
decimal_places_rounding = 1
repetitions_montecarlo = 10000

def calculate_SDSM_exhaustive(df, sample_size, column_name="Height"): # We must take into account the probabilities!
    unique_heights = df[column_name].values
    unique_probabilities = df['Probability'].values
    # Generate all possible combinations
    all_combs = list(product(unique_heights, repeat=sample_size))
    # Calculate their probabilities and mean
    probabilities = []
    means = []
    for comb in all_combs:
        prob = np.prod([unique_probabilities[np.where(unique_heights == x)[0][0]] for x in comb])
        mean = np.mean(comb)
        probabilities.append(prob)
        means.append(mean)
    # Create df_combinations
    df_combinations = pd.DataFrame({
        'Combination': all_combs,
        'Mean': means,
        'Probability': probabilities
    })
    # Calculate empirical SE (
    empirical_SE = np.sqrt(np.sum([p * m**2 for p, m in zip(probabilities, means)]) - np.sum([p * m for p, m in zip(probabilities, means)])**2)
    return df_combinations, empirical_SE

def calculate_SDSM_montecarlo(df, sample_size, repetitions_montecarlo, column_name="Height"):
    # Extract the height and probability data
    heights = df[column_name].values
    probabilities = df['Probability'].values
    # Initialize an array to store the sample means
    sample_means = np.zeros(repetitions_montecarlo)
    # Generate sample means according to the given probabilities
    for i in range(repetitions_montecarlo):
        random_sample = np.random.choice(heights, size=sample_size, p=probabilities)
        sample_means[i] = np.mean(random_sample)
    # Calculate the empirical Standard Error (SE)
    empirical_SE = np.std(sample_means, ddof=1)
    # Create a df with the sample means
    df_combinations = pd.DataFrame({'Mean': sample_means})
    return df_combinations, empirical_SE 

def rectify_means(df, decimal_places=2):
    # Rectify the means by rounding
    df['Mean_rectified'] = df['Mean'].round(decimal_places)
    if 'Probability' in df.columns:
        # Group by the rectified mean and sum the probabilities
        grouped_df = df.groupby('Mean_rectified').agg(
            Count=pd.NamedAgg(column='Mean', aggfunc='size'),
            Probability=pd.NamedAgg(column='Probability', aggfunc='sum')
        ).reset_index()
        probabilities = grouped_df['Probability'].values
    else:
        # Group by the rectified mean and count the occurrences
        grouped_df = df.groupby('Mean_rectified').agg(
            Count=pd.NamedAgg(column='Mean', aggfunc='size')
        ).reset_index()
        # Create a Probability column based on the counts
        total_count = grouped_df['Count'].sum()
        grouped_df['Probability'] = grouped_df['Count'] / total_count
        probabilities = grouped_df['Probability'].values
    # Calculate the weighted mean of Mean_rectified
    mean_rectified_values = grouped_df['Mean_rectified'].values
    weighted_mean = np.sum(probabilities * mean_rectified_values)
    # Calculate the weighted standard deviation of Mean_rectified
    weighted_var = np.sum(probabilities * (mean_rectified_values - weighted_mean)**2)
    weighted_std = np.sqrt(weighted_var)
    return grouped_df, weighted_std

def plot_sdsm(df_grouped, sample_size, ax, column_name='Mean_rectified', label=None):
    mean_counts = df_grouped
    ax.scatter(mean_counts[column_name], mean_counts['Count'], alpha=0.7, s=50)
    line, = ax.plot(mean_counts[column_name], mean_counts['Count'], linewidth=0.8, label=label)  # Note the comma; unpacks the list returned by ax.plot
    for _, row in mean_counts.iterrows():
        ax.plot([row[column_name], row[column_name]], [0, row['Count']], linestyle='--', color='grey', linewidth=0.5)

    ax.xaxis.set_major_formatter(FormatStrFormatter('%.2f'))
    ax.set_xlabel(column_name)
    ax.set_ylabel('Count')
    return line  # Return the line handle for legend

def compare_empirical_estimated_SE(mean_pop, empirical_SE, pop_std, sample_size):
    theoretical_SE = pop_std / np.sqrt(sample_size)
    print(f"Mini pop mean: {mean_pop:.2f}")
    print(f"Mini pop std: {pop_std:.2f}")
    print(f"SDSM sample size: {sample_size}")
    print(f"SDSM empirical SE: {empirical_SE:.2f}")
    print(f"SDSM theoretical SE (from mini pop std): {theoretical_SE:.2f}")
    print_color(f"SDSM empirical SE / theoretical SE: {(empirical_SE/theoretical_SE) * 100:.2f}%", "black", "bold", "italic", "small")
    
print('')
print_color('SDSM mini pop 01 estimated by the exhaustive method:', "black", "bold", font_size="large")
df_sdsm_mini_pop_01_exhaustive, _ = calculate_SDSM_exhaustive(df_mini_pop_01, sample_size_mini_pop_01)
df_sdsm_mini_pop_01_exhaustive_rectified, SE_sdsm_mini_pop_01_exhaustive_rectified = rectify_means(df_sdsm_mini_pop_01_exhaustive, decimal_places_rounding)
display(df_sdsm_mini_pop_01_exhaustive_rectified)
# Plot 
fig, ax = plt.subplots(figsize=(3, 3))
plot_sdsm(df_sdsm_mini_pop_01_exhaustive_rectified, sample_size_mini_pop_01, ax, column_name='Mean_rectified')
ax.set_title(f"SDSM 01 exhaustive (n = {sample_size_mini_pop_01})")
ax.set_xlabel('Mean_rectified')
ax.set_ylabel('Count')
plt.tight_layout()
plt.show()
compare_empirical_estimated_SE(mean_mini_pop_01, SE_sdsm_mini_pop_01_exhaustive_rectified, std_mini_pop_01, sample_size_mini_pop_01)

print('')
print_color('SDSM mini pop 01 estimated by the monte carlo method:', "black", "bold", font_size="large")
df_sdsm_mini_pop_01_montecarlo, _ = calculate_SDSM_montecarlo(df_mini_pop_01, sample_size_mini_pop_01, repetitions_montecarlo)
df_sdsm_mini_pop_01_montecarlo_rectified, SE_sdsm_mini_pop_01_montecarlo_rectified = rectify_means(df_sdsm_mini_pop_01_montecarlo, decimal_places_rounding)
display(df_sdsm_mini_pop_01_montecarlo_rectified)
# Plot 
fig, ax = plt.subplots(figsize=(3, 3))
plot_sdsm(df_sdsm_mini_pop_01_montecarlo_rectified, sample_size_mini_pop_01, ax, column_name='Mean_rectified')
ax.set_title(f"SDSM 01 montecarlo (n = {sample_size_mini_pop_01})")
ax.set_xlabel('Mean_rectified')
ax.set_ylabel('Count')
plt.tight_layout()
plt.show()
compare_empirical_estimated_SE(mean_mini_pop_01, SE_sdsm_mini_pop_01_montecarlo_rectified, std_mini_pop_01, sample_size_mini_pop_01)


sample_size_mini_pop_02 = 7

print('')
print_color('SDSM mini pop 02 estimated by the exhaustive method:', "black", "bold", font_size="large")
df_sdsm_mini_pop_02_exhaustive, _ = calculate_SDSM_exhaustive(df_mini_pop_02, sample_size_mini_pop_02)
df_sdsm_mini_pop_02_exhaustive_rectified, SE_sdsm_mini_pop_02_exhaustive_rectified = rectify_means(df_sdsm_mini_pop_02_exhaustive, decimal_places_rounding)
display(df_sdsm_mini_pop_02_exhaustive_rectified)
fig, ax = plt.subplots(figsize=(3, 3))
plot_sdsm(df_sdsm_mini_pop_02_exhaustive_rectified, sample_size_mini_pop_02, ax, column_name='Mean_rectified')
ax.set_title(f"SDSM 02 exhaustive (n = {sample_size_mini_pop_02})")
ax.set_xlabel('Mean_rectified')
ax.set_ylabel('Count')
plt.tight_layout()
plt.show()
compare_empirical_estimated_SE(mean_mini_pop_02, SE_sdsm_mini_pop_02_exhaustive_rectified, std_mini_pop_02, sample_size_mini_pop_02)

print('')
print_color('SDSM mini pop 02 estimated by the monte carlo method:', "black", "bold", font_size="large")
df_sdsm_mini_pop_02_montecarlo, _ = calculate_SDSM_montecarlo(df_mini_pop_02, sample_size_mini_pop_02, repetitions_montecarlo)
df_sdsm_mini_pop_02_montecarlo_rectified, SE_sdsm_mini_pop_02_montecarlo_rectified = rectify_means(df_sdsm_mini_pop_02_montecarlo, decimal_places_rounding)
display(df_sdsm_mini_pop_02_montecarlo_rectified)
fig, ax = plt.subplots(figsize=(3, 3))
plot_sdsm(df_sdsm_mini_pop_02_montecarlo_rectified, sample_size_mini_pop_02, ax, column_name='Mean_rectified')
ax.set_title(f"SDSM 02 montecarlo (n = {sample_size_mini_pop_02})")
ax.set_xlabel('Mean_rectified')
ax.set_ylabel('Count')
plt.tight_layout()
plt.show()
compare_empirical_estimated_SE(mean_mini_pop_02, SE_sdsm_mini_pop_02_montecarlo_rectified, std_mini_pop_02, sample_size_mini_pop_02)





alpha_mini_pop_01 = 0.05

def generate_random_sample(df_mini_pop, sample_size):
    normalized_probabilities = df_mini_pop['Probability'] / df_mini_pop['Probability'].sum()
    sampled_means = np.random.choice(df_mini_pop['Height'], size=sample_size, p=normalized_probabilities)
    unique_values, counts = np.unique(sampled_means, return_counts=True)
    sampled_df = pd.DataFrame({'Height': unique_values, 'Count': counts})
    return sampled_df

def calculate_sample_z_score(sample_mean, population_mean, population_std):
    sample_z_score = (sample_mean - population_mean) / population_std
    return sample_z_score

def plot_z_distribution(sample_z_score, alpha, title):
    x = np.linspace(-4, 4, 400)  # Range of z-scores
    plt.figure(figsize=(5, 3))
    plt.plot(x, stats.norm.pdf(x), color='blue', label='Z-Distribution')
    x_fill = np.linspace(-4, -abs(stats.norm.ppf(alpha/2)), 100)  # Area to shade above alpha/2 on the left tail
    plt.fill_between(x_fill, stats.norm.pdf(x_fill), color='blue', alpha=0.2)
    x_fill = np.linspace(abs(stats.norm.ppf(alpha/2)), 4, 100)  # Area to shade above alpha/2 on the right tail
    plt.fill_between(x_fill, stats.norm.pdf(x_fill), color='blue', alpha=0.2)
    plt.scatter(sample_z_score, 0, color='red', label=f'Sample Z-Score', zorder=5)
    # Add texts for p < alpha and p > alpha
    plt.text(-3.5, 0.02, r'$p < \alpha/2$', fontsize=12, ha='center', color='black')
    plt.text(3.5, 0.02, r'$p < \alpha/2$', fontsize=12, ha='center', color='black')
    plt.xlabel('Z-Score')
    plt.ylabel('Density')
    plt.title(title)
    alpha_x = abs(stats.norm.ppf(alpha/2))
    alpha_patch = mpatches.Patch(color='blue', alpha=0.2, label=f'$\\alpha$/2 ({alpha * 100}%): $\\pm${alpha_x:.2f}')
    plt.legend(handles=[alpha_patch], loc='upper right', bbox_to_anchor=(1.5, 1))
    plt.grid(True)
    plt.show()
    
def decision_z_distribution(mean_pop, mean_sample, sample_z_score, sample_size, alpha):
    df = sample_size - 1
    # Calculate the two-tailed p-value
    p_value = 2 * (1 - norm.cdf(abs(sample_z_score)))
    # print(f"Decision: Because z({df}) = {sample_z_score:.4f}, p = {p_value:.4f} < {alpha} (two-tailed z-test),", end=" ")
    print_color(f"Decision: z({df}) = {sample_z_score:.4f}, p = {p_value:.4f} < {alpha} (two-tailed z-test):", "black", "bold")
    if p_value < alpha:
         print_color(f"the null hypothesis can be rejected.\nThe sample mean (= {mean_sample}) is significantly different from the population mean (= {mean_pop}).", 'green', 'bold')
    else:
        print_color(f"the null hypothesis can NOT be rejected.\nThe sample mean (= {mean_sample}) is NOT significantly different from the population mean (= {mean_pop}).", 'red', 'bold')

print_color('Mini pop 01', "black", "bold", font_size="large")
print(f"Mean: {mean_mini_pop_01}")
print(f"Std: {std_mini_pop_01:.2f}")
# Random sample following the normal probabilites
df_random_sample_mini_pop_01 = generate_random_sample(df_mini_pop_01, sample_size_mini_pop_01)
mean_random_sample_mini_pop_01 = calculate_weighted_mean(df_random_sample_mini_pop_01['Height'], df_random_sample_mini_pop_01['Count']).round(4)
std_random_sample_mini_pop_01 = calculate_weighted_std(df_random_sample_mini_pop_01['Height'], df_random_sample_mini_pop_01['Count']).round(4)
z_score_random_sample_mini_pop_01 = calculate_sample_z_score(mean_random_sample_mini_pop_01, mean_mini_pop_01, std_mini_pop_01)
print("\nRandom sample ")
display(df_random_sample_mini_pop_01)
print(f"Sample size: {df_random_sample_mini_pop_01['Count'].sum()}")
print(f"Mean: {mean_random_sample_mini_pop_01}")
print(f"Std: {std_random_sample_mini_pop_01:.2f}")
print(f"Z-score: {z_score_random_sample_mini_pop_01:.2f}")
plot_z_distribution(z_score_random_sample_mini_pop_01, alpha_mini_pop_01, 'Z-Distribution mini pop 01')
decision_z_distribution(mean_mini_pop_01, mean_random_sample_mini_pop_01, z_score_random_sample_mini_pop_01, sample_size_mini_pop_01, alpha_mini_pop_01)
          
# Extreme sample
extreme_sample_mini_pop_01_dict = {'Height': [df_mini_pop_01['Height'].iloc[-2], df_mini_pop_01['Height'].iloc[-1]], 'Count': [1, sample_size_mini_pop_01 - 1]}
df_extreme_sample_mini_pop_01 = pd.DataFrame(extreme_sample_mini_pop_01_dict)
mean_extreme_sample_mini_pop_01 = calculate_weighted_mean(df_extreme_sample_mini_pop_01['Height'], df_extreme_sample_mini_pop_01['Count']).round(4)
std_extreme_sample_mini_pop_01 = calculate_weighted_std(df_extreme_sample_mini_pop_01['Height'], df_extreme_sample_mini_pop_01['Count']).round(4)
z_score_extreme_sample_mini_pop_01 = calculate_sample_z_score(mean_extreme_sample_mini_pop_01, mean_mini_pop_01, std_mini_pop_01)
print("\nExtreme sample ")
display(df_extreme_sample_mini_pop_01)
print(f"Sample size: {df_extreme_sample_mini_pop_01['Count'].sum()}")
print(f"Mean: {mean_extreme_sample_mini_pop_01}")
print(f"Std: {std_extreme_sample_mini_pop_01:.2f}")
print(f"Z-score: {z_score_extreme_sample_mini_pop_01:.2f}")
plot_z_distribution(z_score_extreme_sample_mini_pop_01, alpha_mini_pop_01, 'Z-Distribution mini pop 01')
decision_z_distribution(mean_mini_pop_01, mean_extreme_sample_mini_pop_01, z_score_extreme_sample_mini_pop_01, sample_size_mini_pop_01, alpha_mini_pop_01)





alpha_mini_pop_02 = 0.05

# Random sample following the normal probabilites
df_random_sample_mini_pop_02 = generate_random_sample(df_mini_pop_02, sample_size_mini_pop_02)
mean_random_sample_mini_pop_02 = calculate_weighted_mean(df_random_sample_mini_pop_02['Height'], df_random_sample_mini_pop_02['Count']).round(4)
std_random_sample_mini_pop_02 = calculate_weighted_std(df_random_sample_mini_pop_02['Height'], df_random_sample_mini_pop_02['Count']).round(4)
z_score_random_sample_mini_pop_02 = calculate_sample_z_score(mean_random_sample_mini_pop_02, mean_mini_pop_02, std_mini_pop_02)
print("Mini pop 02\n")
print(f"Mean: {mean_mini_pop_02}")
print(f"Std: {std_mini_pop_02:.2f}")
print("\nRandom sample ")
display(df_random_sample_mini_pop_02)
print(f"Sample size: {df_random_sample_mini_pop_02['Count'].sum()}")
print(f"Mean: {mean_random_sample_mini_pop_02}")
print(f"Std: {std_random_sample_mini_pop_02:.2f}")
print(f"Z-score: {z_score_random_sample_mini_pop_02:.2f}")
plot_z_distribution(z_score_random_sample_mini_pop_02, alpha_mini_pop_02, 'Z-Distribution mini pop 02')
decision_z_distribution(mean_mini_pop_02, mean_random_sample_mini_pop_02, z_score_random_sample_mini_pop_02, sample_size_mini_pop_02, alpha_mini_pop_02)

# Extreme sample
extreme_sample_mini_pop_02_dict = {'Height': [df_mini_pop_02['Height'].iloc[-2], df_mini_pop_02['Height'].iloc[-1]], 'Count': [1, sample_size_mini_pop_02 - 1]}
df_extreme_sample_mini_pop_02 = pd.DataFrame(extreme_sample_mini_pop_02_dict)
mean_extreme_sample_mini_pop_02 = calculate_weighted_mean(df_extreme_sample_mini_pop_02['Height'], df_extreme_sample_mini_pop_02['Count']).round(4)
std_extreme_sample_mini_pop_02 = calculate_weighted_std(df_extreme_sample_mini_pop_02['Height'], df_extreme_sample_mini_pop_02['Count']).round(4)
z_score_extreme_sample_mini_pop_02 = calculate_sample_z_score(mean_extreme_sample_mini_pop_02, mean_mini_pop_02, std_mini_pop_02)
print("\nExtreme sample ")
display(df_extreme_sample_mini_pop_02)
print(f"Sample size: {df_extreme_sample_mini_pop_02['Count'].sum()}")
print(f"Mean: {mean_extreme_sample_mini_pop_02}")
print(f"Std: {std_extreme_sample_mini_pop_02:.2f}")
print(f"Z-score: {z_score_extreme_sample_mini_pop_02:.2f}")
plot_z_distribution(z_score_extreme_sample_mini_pop_02, alpha_mini_pop_02, 'Z-Distribution mini pop 02')
decision_z_distribution(mean_mini_pop_02, mean_extreme_sample_mini_pop_02, z_score_extreme_sample_mini_pop_02, sample_size_mini_pop_02, alpha_mini_pop_02)











# Define x values
x = np.linspace(-5, 5, 1000)

# Standard normal (z-distribution) pdf
z_pdf = norm.pdf(x)

# Plot z-distribution
plt.plot(x, z_pdf, label='Standard Normal (z)', color='black', linewidth=2)

# Plot t-distributions for different degrees of freedom
dfs = [1, 2, 5, 30]  # Degrees of freedom
colors = ['red', 'blue', 'green', 'purple']

for df, color in zip(dfs, colors):
    t_pdf = t.pdf(x, df)
    plt.plot(x, t_pdf, label=f't (df={df})', color=color)

plt.title('Standard Normal (z) vs. t-distributions')
plt.xlabel('x')
plt.ylabel('Probability Density')
plt.legend()
plt.grid(True)
plt.show()





# Given values
mu = 400          # Population mean
sigma = 40        # Population standard deviation
sample_mean = 392 # Sample mean
n = 5             # Sample size
sample_std = sigma / np.sqrt(n)  # Standard error (std. deviation of sample means)
df = n - 1        # Degrees of freedom for t-distribution

# Generate data for plotting
x = np.linspace(mu - 4*sigma, mu + 4*sigma, 1000)

# Now using a Gaussian for population distribution
y = norm.pdf(x, mu, sigma)

y_sample = norm.pdf(x, mu, sample_std)
y_tdist = t.pdf(x, df, mu, sample_std) # t-distribution

# Define the plots in a 2x2 grid
fig, axes = plt.subplots(2, 2, figsize=(14, 6))

# Adjust xlim and ylim for all plots
xlims = (min(x), max(x))
ylims = (0, max(y_sample) + 0.002)

def plot_population_distribution(ax, title, sigma_text):
    ax.plot(x, y, label='Population Distribution')
    ax.plot([mu, mu], [0, norm.pdf(mu, mu, sigma)], 'red', label='Population Mean (μ)')
    
    # Adjusting the horizontal line for standard deviation
    height_at_sigma = norm.pdf(mu + sigma, mu, sigma)
    ax.hlines(y=height_at_sigma, xmin=mu, xmax=mu+sigma, color='red', linestyle=':', label='Standard Deviation (σ)')
    ax.annotate(sigma_text, xy=(mu + sigma, height_at_sigma), xytext=(10,10), textcoords='offset points', arrowprops=dict(arrowstyle="->"), fontsize=10)
    
    ax.set_title(title)
    ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))
    ax.set_xlim(xlims)
    ax.set_ylim(ylims)
    ax.set_xlabel("Value")
    ax.set_ylabel("Density")

def plot_sampling_distribution(ax, y_data, title, annotation):
    if y_data is y_sample:  # If it's a normal distribution
        height_at_mu = norm.pdf(mu, mu, sample_std)
    else:  # If it's a t-distribution
        height_at_mu = t.pdf(mu, df, mu, sample_std)

    ax.plot(x, y_data, label='Sampling Distribution')
    ax.plot([mu, mu], [0, height_at_mu], 'red', label='Mean of sample means (= μ)')
    ax.hlines(y=norm.pdf(mu + sample_std, mu, sample_std), xmin=mu, xmax=mu+sample_std, linestyle=':', color='red', label='Standard Error')
    ax.axvline(x=sample_mean, color='blue', linestyle='--', label='Sample Mean (M)')
    ax.annotate(annotation, xy=(mu + sample_std, norm.pdf(mu + sample_std, mu, sample_std)), xytext=(10,-10), textcoords='offset points', arrowprops=dict(arrowstyle="->"), fontsize=10)
    ax.set_title(title)
    ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))
    ax.set_xlim(xlims)
    ax.set_ylim(ylims)
    ax.set_xlabel("Mean of value")
    ax.set_ylabel("Density")

    
# UPPER LEFT: Population Distribution (Gaussian)
plot_population_distribution(axes[0,0], 'Population distribution (normal)', f'σ = {sigma:.2f}')

# UPPER RIGHT: Sampling Distribution of the Sample Means (Normal Distribution)
plot_sampling_distribution(axes[0,1], y_sample, 'SDMS: z-distribution (Gaussian)', r'$\sigma_M = \frac{\sigma}{\sqrt{n}}$')

# LOWER LEFT: Population Distribution (Gaussian)
plot_population_distribution(axes[1,0], 'Population distribution (normal)', 'σ = ?')

# LOWER RIGHT: Sampling Distribution of the Sample Means (t-distribution)
plot_sampling_distribution(axes[1,1], y_tdist, 'SDMS: t-distribution', r'$s_M = \frac{s}{\sqrt{n}},  s = \sqrt{\frac{SS}{df}}$')

plt.tight_layout()
plt.show()

# Delete all variables of this block
del mu, sigma, sample_mean, n, sample_std, df, x, y, y_sample, y_tdist, fig, axes, xlims, ylims





# Define the significance levels for one-tailed tests
alpha_values_one_tail = [0.25, 0.1, 0.05, 0.025, 0.01, 0.005]

# Convert them to two-tailed values (double the one-tail values)
alpha_values_two_tail = [alpha * 2 for alpha in alpha_values_one_tail]

# Define degrees of freedom range
df_range = list(range(1, 31))

# Populate the table
data = {}
for alpha_1, alpha_2 in zip(alpha_values_one_tail, alpha_values_two_tail):
    t_values = [t.ppf(1 - alpha_2/2, df) for df in df_range]  # Adjusted to take the correct percentile for two-tail alpha values
    data[(f'One-tail: α = {alpha_1}' if alpha_1 == 0.25 else f'α = {alpha_1}', 
         f'Two-tails: α = {alpha_2}' if alpha_2 == 0.5 else f'α = {alpha_2}')] = t_values

# Create dataframe
t_table = pd.DataFrame(data, index=df_range)
t_table.index.name = "Degrees of Freedom"
t_table.name = "T-Distribution Table"

display(t_table)





def check_normality(df, column_name="Height"):
    # Convert the 'Count' column to integers
    df['Count'] = df['Count'].astype(int)
     # Create an empty list to store the expanded dataset
    expanded_data = []
    # Loop through each row in the dataframe
    for i, row in df.iterrows():
        height = row[column_name]
        count = int(row["Count"])  # Explicitly casting to int for safety
        # Add 'count' number of 'height' values to the expanded dataset
        expanded_data.extend([height] * count)
    # Convert the list to a NumPy array
    expanded_data_array = np.array(expanded_data)
    # Perform the Shapiro-Wilk test
    shapiro_stat, shapiro_p = stats.shapiro(expanded_data_array)
    print(f"Shapiro-Wilk test statistic: {shapiro_stat}")
    print(f"P-value: {shapiro_p}")
    if shapiro_p > 0.05:
        print_color('Data follows a normal distribution!', 'green', 'bold')
    else:
        print_color('Data does NOT follow a normal distribution!', 'red', 'bold')
    # Return the test statistic and p-value
    return shapiro_stat, shapiro_p

# Execute the function
print('Mini pop 01:')
shapiro_stat, shapiro_p = check_normality(df_mini_pop_01)
print('\nMini pop 02:')
shapiro_stat, shapiro_p = check_normality(df_mini_pop_02)





def reconstruct_sample(df):
    if "Height" in df.columns and "Count" in df.columns:
        heights = df["Height"].values
        counts = df["Count"].values
        sample = np.repeat(heights, counts)
        return sample
    else:
        raise ValueError("Input dataframe must have 'Height' and 'Count' columns")
        
def sum_squared_deviations(np_array):
    mean_val = np.mean(np_array)
    deviations = np_array - mean_val
    squared_deviations = deviations**2
    ss = np.sum(squared_deviations)
    return  ss

def sample_variance(degf, sum_squared_deviations):
    if degf <= 0:
        raise ValueError("Degrees of freedom must be greater than 0.")
    return sum_squared_deviations / degf

def estimated_standard_error(sample_var, n):
    if n <= 1:
        raise ValueError("Sample size must be greater than 1.")
    return np.sqrt(sample_var / n)

def t_score(sample_mean, expected_mean, estimated_standard_error):
    t = (sample_mean - expected_mean) / estimated_standard_error
    return t

def lookup_t_value(degf, alpha, test_type="two-tailed"):
    
    if degf not in t_table.index:
        raise ValueError(f"The degrees of freedom {degf} does not exist in the table.")
    
    if test_type == "two-tailed":
        if alpha not in [0.5, 0.2, 0.1, 0.05, 0.02, 0.01]:
            raise ValueError(f"The alpha value {alpha} does not exist in the table for a two-tailed t-test.")
    elif test_type == "one-tailed":
        if alpha not in [0.25, 0.1, 0.05, 0.025, 0.01, 0.005]:
            raise ValueError(f"The alpha value {alpha} does not exist in the table for a one-tailed t-test.")
    else:
        raise ValueError("test_type should be either 'one-tailed' or 'two-tailed'.")
    
    # Determine which level of the multi-index to look in based on test_type
    if test_type == "one-tailed":
        # Upper level for one-tail
        column_label = f'α = {alpha}'
        if column_label not in t_table.columns.get_level_values(0):
            column_label = 'One-tail: ' + column_label
        return t_table.xs(key=column_label, axis=1, level=0).loc[degf].values[0]
    elif test_type == "two-tailed":
        # Lower level for two-tails
        column_label = f'α = {alpha}'
        if column_label not in t_table.columns.get_level_values(1):
            column_label = 'Two-tails: ' + column_label
        return t_table.xs(key=column_label, axis=1, level=1).loc[degf].values[0]

def plot_results_ttest(data, expected_mean, t_stat, alpha=0.05):
    # Calculate the sample mean, standard deviation, and standard error
    sample_mean = np.mean(data)
    s = np.std(data, ddof=1)
    n = len(data)
    estimated_std = s / np.sqrt(n)
    # Degrees of freedom for t-distribution
    degf = n - 1
    # Create t-distribution curve
    x = np.linspace(expected_mean - 4*estimated_std, expected_mean + 4*estimated_std, 400)
    y = t.pdf(x, degf, loc=expected_mean, scale=estimated_std)
    # Maximum height of t-distribution
    y_max = max(y)
    # Calculate height of t-distribution curve at expected_mean + 1 estimated standard deviation
    y_intercept = t.pdf(expected_mean + estimated_std, degf, loc=expected_mean, scale=estimated_std)
    # Critical values for shading
    left_critical = expected_mean + t.ppf(alpha/2, degf)*estimated_std
    right_critical = expected_mean + t.ppf(1 - alpha/2, degf)*estimated_std
    # Create the plot
    plt.figure(figsize=(9, 5))
    # Plot t-distribution curve
    plt.plot(x, y)
    # Shade the tails
    plt.fill_between(x, y, where=(x < left_critical) | (x > right_critical), alpha=0.5, label=f'Two tailed at α = {alpha}')
    # Plot red vertical line from 0 to its intersection with t-distribution
    plt.plot([expected_mean, expected_mean], [0, y_max], color='red', label=f'Expected Mean: {expected_mean}')
    # Plot SE line
    plt.plot([expected_mean, expected_mean + estimated_std], [y_intercept, y_intercept], color='red', linestyle='--')
    # Add a quotation mark above the SE line
    SE_line_center_x = expected_mean + 0.5*estimated_std
    SE_line_center_y = y_intercept + 0.001
    plt.text(SE_line_center_x, SE_line_center_y, f'σ\u2098 ≈ {estimated_std:.2f}', ha='center', va='bottom', fontsize=8)
    # Plot red dot at sample mean
    plt.plot(sample_mean, 0, 'ro', label=f'Sample Mean: {sample_mean:.2f}')
    # Remove y-ticks
    plt.yticks([])
    # Title, labels, legend, and y limits
    plt.title('Solved T-distribution (SDMS)')
    plt.xlabel('Sample mean of IRV')
    plt.ylabel('Density')
    plt.ylim(0)
    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))
    plt.tight_layout()
    plt.show()
        
def decision_ttest(t_sample, degf, alpha, t_alpha, sample_mean, sample_std, expected_mean, test_type): 
    if abs(t_sample) >= t_alpha:  
         print_color(f"We reject H0. Our sample (M = {sample_mean:.2f}, SD = {sample_std:.2f}) is significantly different ({test_type} t-test, t({degf}) = {t_sample:.4f}, p < {alpha}) than the population norm (M = {expected_mean:.2f}).", "green", "bold")
    else:
         print_color(f"We accept H0. Our sample (M = {sample_mean:.2f}, SD = {sample_std:.2f}) is not significantly different ({test_type} t-test, t({degf}) = {t_sample:.4f}, p < {alpha}) than the population norm (M = {expected_mean:.2f}).", "red", "bold")

#[Optional]
def critical_values(t_alpha, expected_mean, estimated_standard_error):
    left_critical =  expected_mean - t_alpha * estimated_standard_error
    right_critical = expected_mean + t_alpha * estimated_standard_error
    return left_critical, right_critical
    
    
alpha = 0.05
test_type = "two-tailed"

# # Get an independent random sample with replacement (not taking into account the population PMF)
# size_sample_ttest_mini_pop_01 = 10
# sample_ttest_mini_pop_01 = df_mini_pop_01['Height'].sample(size_sample_ttest_mini_pop_01, replace=True)
# print(sample_ttest_mini_pop_01.tolist())

# Reconstruct samples

random_sample_ttest_mini_pop_01 = reconstruct_sample(df_random_sample_mini_pop_01)
extreme_sample_ttest_mini_pop_01 = reconstruct_sample(df_extreme_sample_mini_pop_01)

# Sum of squared deviations
sum_sq_dev_random_sample_mini_pop_01 = sum_squared_deviations(random_sample_ttest_mini_pop_01)
sum_sq_dev_extreme_sample_mini_pop_01 = sum_squared_deviations(extreme_sample_ttest_mini_pop_01)

# Sample Variance
degf_random_sample_mini_pop_01 = len(random_sample_ttest_mini_pop_01) - 1
sample_var_random_sample_mini_pop_01 = sample_variance(degf_random_sample_mini_pop_01, sum_sq_dev_random_sample_mini_pop_01)

degf_extreme_sample_mini_pop_01 = len(extreme_sample_ttest_mini_pop_01) - 1
sample_var_extreme_sample_mini_pop_01 = sample_variance(degf_extreme_sample_mini_pop_01, sum_sq_dev_extreme_sample_mini_pop_01)

# Estimated Standard Error
est_std_err_random_sample_mini_pop_01 = estimated_standard_error(sample_var_random_sample_mini_pop_01, len(random_sample_ttest_mini_pop_01))
est_std_err_extreme_sample_mini_pop_01 = estimated_standard_error(sample_var_extreme_sample_mini_pop_01, len(extreme_sample_ttest_mini_pop_01))

# t-statistic
mean_random_sample_ttest_mini_pop_01 = round(np.mean(random_sample_ttest_mini_pop_01), decimal_places_rounding)
t_random_sample_ttest_mini_pop_01 = t_score(mean_random_sample_ttest_mini_pop_01, mean_mini_pop_01, est_std_err_random_sample_mini_pop_01)

mean_extreme_sample_ttest_mini_pop_01 = round(np.mean(extreme_sample_ttest_mini_pop_01), decimal_places_rounding)
t_extreme_sample_ttest_mini_pop_01 = t_score(mean_extreme_sample_ttest_mini_pop_01, mean_mini_pop_01, est_std_err_extreme_sample_mini_pop_01)

# t value at the required alpha
t_alpha = lookup_t_value(degf_random_sample_mini_pop_01, alpha, test_type)

# [Optional]: Find the critical values
# left_critical, right_critical = critical_values(t_alpha, mean_mini_pop_01, est_std_err_random_sample_mini_pop_01)

# Result
print_color("Random sample mini pop 01", "black", "bold")
print(random_sample_ttest_mini_pop_01)
plot_results_ttest(random_sample_ttest_mini_pop_01, mean_mini_pop_01, t_random_sample_ttest_mini_pop_01, alpha)
decision_ttest(t_random_sample_ttest_mini_pop_01, degf_random_sample_mini_pop_01, alpha, t_alpha, mean_random_sample_ttest_mini_pop_01, est_std_err_random_sample_mini_pop_01, mean_mini_pop_01, test_type)
print("")
print_color("Extreme sample mini pop 01", "black", "bold")
print(extreme_sample_ttest_mini_pop_01)
plot_results_ttest(extreme_sample_ttest_mini_pop_01, mean_mini_pop_01, t_extreme_sample_ttest_mini_pop_01, alpha)
decision_ttest(t_extreme_sample_ttest_mini_pop_01, degf_extreme_sample_mini_pop_01, alpha, t_alpha, mean_extreme_sample_ttest_mini_pop_01, est_std_err_extreme_sample_mini_pop_01, mean_mini_pop_01, test_type)





alpha = 0.05

t_stat, p_value = ttest_1samp(random_sample_ttest_mini_pop_01, mean_mini_pop_01)
print(f"df = {degf_random_sample_mini_pop_01}\nt = {t_stat}\np = {p_value}")
print('')
if p_value < 0.05:
    print_color(f"RESULT: The p-value is {p_value:.4f}. This is less than {alpha}, so we reject H0. The average score of the class, {mean_random_sample_ttest_mini_pop_01}, is significantly different from the population mean {mean_mini_pop_01}.", "green", "bold")
else:
    print_color(f"RESULT: The p-value is {p_value:.4f}. This is more than {alpha}, so we DON'T reject H0. The average score of the class, {mean_random_sample_ttest_mini_pop_01}, is NOT significantly different from the populaiton mean {mean_mini_pop_01}.", "green", "bold")








def calculate_difference_sdm(df_a, df_b):
    # Initialize an empty list to store the results
    results = []
    
    # Loop through all the rows in df_a and df_b to generate all possible combinations
    for index_a, row_a in df_a.iterrows():
        for index_b, row_b in df_b.iterrows():
            # Calculate the difference
            difference = row_a['Mean rectified'] - row_b['Mean rectified']
            
            # Calculate the probability of this difference occurring
            probability = row_a['Probability'] * row_b['Probability']
            
            # Append the results to the list
            results.append(((row_a['Mean rectified'], row_b['Mean rectified']), difference, probability))
    
    # Convert the list of results to a DataFrame
    df_difference = pd.DataFrame(results, columns=['Combination', 'Difference', 'Probability'])
    
    # Group by the 'Combination' and 'Difference' columns, summing up the probabilities for each unique difference
    df_final = df_difference.groupby(['Combination', 'Difference']).agg({'Probability': 'sum'}).reset_index()
    
    return df_final

# Example dataframes representing SDSMs for population A and B
data_a = {'Mean rectified': [2, 3, 4, 5, 6],
          'Probability': [0.0625, 0.25, 0.3125, 0.25, 0.0625]}
df_a = pd.DataFrame(data_a)

data_b = {'Mean rectified': [7, 8, 9, 10, 11],
          'Probability': [0.0625, 0.25, 0.3125, 0.25, 0.0625]}
df_b = pd.DataFrame(data_b)

# Calculate the SDSM for the difference between sample means of A and B
df_difference = calculate_difference_sdm(df_a, df_b)
display(df_difference)





print(f"Mini pop 01")
print(f"Random sample = {random_sample_ttest_mini_pop_01}")
print(f"Mean sample = {mean_random_sample_ttest_mini_pop_01}")
print(f"Degrees of freedom = {degf_random_sample_mini_pop_01}")
print(f"Sum squared deviations = {sum_sq_dev_random_sample_mini_pop_01:.4f}")
print(f"Estimated SE (std sample) = {est_std_err_random_sample_mini_pop_01:.4f}")

random_sample_ttest_mini_pop_02 = reconstruct_sample(df_random_sample_mini_pop_02)
mean_random_sample_ttest_mini_pop_02 = round(np.mean(random_sample_ttest_mini_pop_02), decimal_places_rounding)
sum_sq_dev_random_sample_mini_pop_02 = sum_squared_deviations(random_sample_ttest_mini_pop_02)
degf_random_sample_mini_pop_02 = len(random_sample_ttest_mini_pop_02) - 1
sample_var_random_sample_mini_pop_02 = sample_variance(degf_random_sample_mini_pop_02, sum_sq_dev_random_sample_mini_pop_02)
est_std_err_random_sample_mini_pop_02 = estimated_standard_error(sample_var_random_sample_mini_pop_02, len(random_sample_ttest_mini_pop_02))
print(f"\nMini pop 02")
print(f"Random sample = {random_sample_ttest_mini_pop_02}")
print(f"Mean sample = {mean_random_sample_ttest_mini_pop_02}")
print(f"Degrees of freedom = {degf_random_sample_mini_pop_02}")
print(f"Sum squared deviations = {sum_sq_dev_random_sample_mini_pop_02:.4f}")
print(f"Estimated SE (std sample) = {est_std_err_random_sample_mini_pop_02:.4f}")

plot_two_mini_pops(df_mini_pop_01, df_mini_pop_02, mean_random_sample_ttest_mini_pop_01, mean_random_sample_ttest_mini_pop_02)





def sum_diff_pmf(array_1, prob_array_1, array_2, prob_array_2, operation='sum'): # operation = 'sum' or 'difference'
    
    partial_df = pd.DataFrame(columns=["array_1", "array_2", "prob_1", "prob_2", operation, "prod_probs"])
    
    # Loop through all combinations of outcomes from array_1 and array_2
    for i, elem_1 in enumerate(array_1):
        for j, elem_2 in enumerate(array_2):
            
            # Get the probabilities
            prob_1 = prob_array_1[i]
            prob_2 = prob_array_2[j]

            # Calculate the operation and its probability
            if operation == "sum":
                res_oper = elem_1 + elem_2
            elif operation == "difference":
                res_oper = elem_1 - elem_2
            else:
               raise ValueError("Operation unknown!")
            
            prod_prob = prob_1 * prob_2

            # Populate the DataFrame
            partial_df = pd.concat([partial_df, pd.DataFrame([{"array_1": elem_1, "array_2": elem_2, "prob_1": prob_1, "prob_2": prob_2, operation: res_oper, "prod_probs": prod_prob}])], ignore_index=True)
    
    df_operation = partial_df[[operation, "prod_probs"]].copy(deep=True).groupby(operation).agg({'prod_probs': 'sum'}).reset_index()

    return partial_df, df_operation

print("SDSM mini pop 01")
display(df_sdsm_mini_pop_01_exhaustive_rectified)

print("SDSM mini pop 02")
display(df_sdsm_mini_pop_02_exhaustive_rectified)

partial_df_sdsm_aminb, df_operation_sdsm_aminb = sum_diff_pmf(df_sdsm_mini_pop_01_exhaustive_rectified["Mean_rectified"], df_sdsm_mini_pop_01_exhaustive_rectified["Probability"], 
             df_sdsm_mini_pop_02_exhaustive_rectified["Mean_rectified"], df_sdsm_mini_pop_02_exhaustive_rectified["Probability"], operation='difference')
display(partial_df_sdsm_aminb, df_operation_sdsm_aminb)








effect = 8 # any linear transformation (?)
noise = np.random.normal(loc=0, scale=1, size=len(df_mini_pop_01))

def plot_two_sdsms(df1, df2, sample_size_01, sample_size_02, label_01=None, label_02=None, column_name='Mean_rectified'):
    fig, ax = plt.subplots(figsize=(8, 6))
    line1 = plot_sdsm(df1, sample_size_01, ax, column_name, label_01)
    line2 = plot_sdsm(df2, sample_size_02, ax, column_name, label_02)
    # Set ylim to include all data points
    max_y1 = df1['Count'].max()
    max_y2 = df2['Count'].max()
    ax.set_ylim(0, max(max_y1, max_y2))
    # Add a combined legend for both lines, outside the plot
    ax.legend(handles=[line1, line2], loc='upper left', bbox_to_anchor=(1, 1))
    plt.tight_layout(rect=[0, 0, 0.85, 1])  # Adjust layout to make room for legend
    plt.show()

def elementwise_difference_distributions(df1, df2, column_name):
    # Create an array where each value of "Mean_rectified" appears "Count" times for both dataframes
    array1 = np.concatenate([np.full(c, m) for m, c in zip(df1[column_name], df1['Count'])])
    array2 = np.concatenate([np.full(c, m) for m, c in zip(df2[column_name], df2['Count'])])
    # Calculate the element-wise differences
    differences = array1 - array2
    # Create a new dataframe with unique "difference_of_means" and "Count"
    df_diff_means_elementwise = pd.DataFrame({'Difference_of_means': differences})
    df_diff_means_elementwise = df_diff_means_elementwise['Difference_of_means'].value_counts().reset_index()
    df_diff_means_elementwise.columns = ['Difference_of_means', 'Count']
    # Sort by "difference_of_means"
    df_diff_means_elementwise = df_diff_means_elementwise.sort_values('Difference_of_means').reset_index(drop=True)
    # Calculate "Probability"
    total_count = df_diff_means_elementwise['Count'].sum()
    df_diff_means_elementwise['Probability'] = df_diff_means_elementwise['Count'] / total_count
    sorted_df_descending = df_diff_means_elementwise.sort_values(by='Difference_of_means', ascending=True)
    return sorted_df_descending
    

print(f"Mini pop 01 not treated")
print(f"Total count of elements: {df_mini_pop_01['Count'].sum()}")
print(f"Mean: {mean_mini_pop_01}")
print(f"Std: {std_mini_pop_01:.2f}")

# Population
# Create a treated pop 01
df_mini_pop_01_treated = df_mini_pop_01.copy(deep=True)
df_mini_pop_01_treated["Height"] = df_mini_pop_01_treated["Height"] + effect + noise

mean_mini_pop_01_treated = calculate_weighted_mean(df_mini_pop_01_treated['Height'], df_mini_pop_01_treated['Count'])
std_mini_pop_01_treated = calculate_weighted_std(df_mini_pop_01_treated['Height'], df_mini_pop_01_treated['Count'])

print(f"\nMini pop 01 treated")
print(f"Total count of elements: {df_mini_pop_01_treated['Count'].sum()}")
print(f"Mean: {mean_mini_pop_01_treated}")
print(f"Std: {std_mini_pop_01_treated:.2f}")

plot_two_mini_pops(df_mini_pop_01, df_mini_pop_01_treated, label_pop_01="Pop 01 not treated", label_pop_02="Pop 01 treated")
display(df_mini_pop_01_treated)

# Difference between populations
df_elementwise_diff_pops = elementwise_difference_distributions(df_mini_pop_01, df_mini_pop_01_treated, "Height")
display(df_elementwise_diff_pops)

fig, ax = plt.subplots(figsize=(4, 4))
plot_mini_population(df_elementwise_diff_pops, ax, "Difference_of_means")
ax.set_title("Distribution pops 01 untreated - treated")
ax.set_xlabel('Height diff (inches)')
ax.set_ylabel('Count')
plt.tight_layout()
plt.show()

# SDSM
df_sdsm_elementwise_diff_pops_exhaustive, _ = calculate_SDSM_exhaustive(df_elementwise_diff_pops, sample_size_mini_pop_01, column_name="Difference_of_means")
df_sdsm_elementwise_diff_pops_exhaustive_rectified, SE_sdsm_elementwise_diff_pops_exhaustive_rectified = rectify_means(df_sdsm_elementwise_diff_pops_exhaustive, decimal_places_rounding)
display(df_sdsm_elementwise_diff_pops_exhaustive_rectified)
fig, ax = plt.subplots(figsize=(3, 3))
plot_sdsm(df_sdsm_elementwise_diff_pops_exhaustive_rectified, sample_size_mini_pop_01, ax, column_name='Mean_rectified')
ax.set_title(f"SDSM 02 elementwise diff pops (n = {sample_size_mini_pop_02})")
ax.set_xlabel('Diff mean rectified')
ax.set_ylabel('Count')
plt.tight_layout()
plt.show()
# print_color(f"SDSM elementwise diff mini pops:", "black", "bold")
# compare_empirical_estimated_SE(mean_mini_pop_01_treated, SE_sdsm_elementwise_diff_pops_exhaustive_rectified, std_mini_pop_01, sample_size_mini_pop_01)
# print('')







# SDSM
df_sdsm_mini_pop_01_treated_exhaustive, _ = calculate_SDSM_exhaustive(df_mini_pop_01_treated, sample_size_mini_pop_01)
df_sdsm_mini_pop_01_treated_exhaustive_rectified, SE_sdsm_mini_pop_01_treated_exhaustive_rectified = rectify_means(df_sdsm_mini_pop_01_treated_exhaustive, decimal_places_rounding)
display(df_sdsm_mini_pop_01_treated_exhaustive_rectified)
print_color(f"Mini pop 01 NOT treated:", "black", "bold")
compare_empirical_estimated_SE(mean_mini_pop_01_treated, SE_sdsm_mini_pop_01_exhaustive_rectified, std_mini_pop_01, sample_size_mini_pop_01)
print('')
print_color(f"Mini pop 01 treated:", "black", "bold")
compare_empirical_estimated_SE(mean_mini_pop_01_treated, SE_sdsm_mini_pop_01_treated_exhaustive_rectified, std_mini_pop_01_treated, sample_size_mini_pop_01)

plot_two_sdsms(df_sdsm_mini_pop_01_exhaustive_rectified, df_sdsm_mini_pop_01_treated_exhaustive_rectified, sample_size_mini_pop_01, sample_size_mini_pop_01, label_01="SDSM 01 not treated", label_02="SDSM 01 treated", column_name='Mean_rectified')

# Element-wise difference between SDSM's
df_diff_means_elementwise = elementwise_difference_means(df_sdsm_mini_pop_01_exhaustive_rectified, df_sdsm_mini_pop_01_treated_exhaustive_rectified)
display(df_diff_means_elementwise)

# Plot
fig, ax = plt.subplots(figsize=(3, 3))
plot_sdsm(df_diff_means_elementwise, sample_size_mini_pop_01, ax, column_name='Difference_of_means')
ax.set_title(f"SDSM 01 (A - B) (n = {sample_size_mini_pop_01})")
ax.set_xlabel('Mean difference')
ax.set_ylabel('Count')
plt.tight_layout()
plt.show()

# print('\nMini pop 02:')
# shapiro_stat, shapiro_p = check_normality(df_diff_means_elementwise, column_name="Difference_of_means")
