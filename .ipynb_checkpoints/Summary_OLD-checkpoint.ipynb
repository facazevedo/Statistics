{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2747c1c3-0b5c-4d9c-8a80-22b945cc683d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.integrate import cumtrapz\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "import scipy.stats as stats\n",
    "import matplotlib.patches as mpatches\n",
    "from scipy.stats import norm\n",
    "from math import ceil\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6509483a-4437-4958-a979-39470878f78d",
   "metadata": {},
   "source": [
    "### Create theoretical population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d936df0e-310b-485c-b2a4-5444d66bdd3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lowest_height_whole_pop= 55\n",
    "highest_height_whole_pop = 85\n",
    "mean_height_whole_pop = 70\n",
    "std_height_whole_pop = 3\n",
    "num_bars_whole_pop = 100\n",
    "n_points_x_axis = 1000\n",
    "\n",
    "def normal_distribution(x, mu, sigma):\n",
    "    pdf_values = (1 / (sigma * np.sqrt(2 * np.pi))) * np.exp(-0.5 * ((x - mu) / sigma) ** 2)\n",
    "    return pdf_values\n",
    "\n",
    "def create_whole_population(f_normal_distribution, lowest_height, highest_height, mean_height, std_height, n_points):\n",
    "    x_values = np.linspace(lowest_height, highest_height, n_points)\n",
    "    pdf_curve = [f_normal_distribution(x, mean_height, std_height) for x in x_values]\n",
    "    return pd.DataFrame({'Height': x_values, 'Density': pdf_curve})\n",
    "\n",
    "def plot_whole_population(df, num_bins, lowest_height, highest_height):\n",
    "    fig, ax = plt.subplots(figsize=(4, 4))\n",
    "    bin_width = (highest_height - lowest_height) / num_bins\n",
    "    mid_x_values = np.linspace(lowest_height, highest_height, num_bins) + bin_width / 2\n",
    "    pdf_values = [df['Density'].iloc[np.argmin(np.abs(df['Height'] - x))] for x in mid_x_values]\n",
    "    ax.plot(df['Height'], df['Density'], label='PDF', color='red', linestyle='dashed', alpha=0.5, linewidth=1.5)\n",
    "    ax.bar(mid_x_values, pdf_values, width=bin_width, alpha=0.5, edgecolor='black', linewidth=0.5, label='Histogram')\n",
    "    ax.set_title('Whole Population of Human Heights')\n",
    "    ax.set_xlabel('Height (inches)')\n",
    "    ax.set_ylabel('Density')\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Create whole population\n",
    "df_whole_pop = create_whole_population(normal_distribution, lowest_height_whole_pop, highest_height_whole_pop, \n",
    "                                       mean_height_whole_pop, std_height_whole_pop, n_points_x_axis)\n",
    "\n",
    "# Plot whole population with histogram bars\n",
    "plot_whole_population(df_whole_pop, num_bars_whole_pop, lowest_height_whole_pop, highest_height_whole_pop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9fed13-366b-4414-b52e-29e8f8f4affa",
   "metadata": {},
   "source": [
    "### Create mini population 01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20665d77-e549-4a3b-b0ee-bbed1e05e571",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lowest_height_mini_pop_01= 55\n",
    "mean_height_mini_pop_01 = 70\n",
    "highest_height_mini_pop_01 = 85\n",
    "std_height_mini_pop_01 = 3\n",
    "num_bars_mini_pop_01 = 100\n",
    "# approx_num_bars_mini_pop_01=9\n",
    "# approx_total_count_mini_pop_01=30\n",
    "approx_num_bars_mini_pop_01=5\n",
    "approx_total_count_mini_pop_01=30\n",
    "\n",
    "def create_mini_population(f_normal_distribution, start, end, n_bins, total_count, mean_height, std_height):\n",
    "    bin_edges = np.linspace(start, end, n_bins + 1)\n",
    "    bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2.0\n",
    "    bin_centers = np.round(bin_centers, 2)  # Round bin_centers to two decimal places\n",
    "    bin_width = (end - start) / n_bins\n",
    "    densities = np.array([np.mean(f_normal_distribution(np.linspace(edge, bin_edges[i+1], 100), mean_height, std_height)) for i, edge in enumerate(bin_edges[:-1])])\n",
    "    float_counts = densities * total_count / sum(densities)\n",
    "    int_counts = np.round(float_counts).astype(int)\n",
    "    non_zero_indices = int_counts != 0\n",
    "    bin_centers = bin_centers[non_zero_indices]\n",
    "    int_counts = int_counts[non_zero_indices]\n",
    "    probabilities = int_counts / sum(int_counts)  # Calculate probabilities\n",
    "    return pd.DataFrame({'Height': bin_centers, 'Count': int_counts, 'Probability': probabilities})\n",
    "\n",
    "def plot_mini_population(df, ax, label):\n",
    "    centers = df['Height']\n",
    "    counts = df['Count']\n",
    "    bin_width = centers.iloc[1] - centers.iloc[0]\n",
    "    ax.bar(centers, counts, width=bin_width, alpha=0.5, edgecolor='black', linewidth=0.5, label=label)\n",
    "    \n",
    "def calculate_weighted_mean(df_col_value, df_col_count):\n",
    "    weighted_mean = (df_col_value * df_col_count).sum() / df_col_count.sum()\n",
    "    return weighted_mean\n",
    "\n",
    "def calculate_weighted_std(df_col_value, df_col_count):\n",
    "    weighted_mean = (df_col_value * df_col_count).sum() / df_col_count.sum()\n",
    "    squared_deviations = ((df_col_value - weighted_mean) ** 2) * df_col_count\n",
    "    weighted_variance = squared_deviations.sum() / df_col_count.sum()\n",
    "    weighted_std = np.sqrt(weighted_variance)\n",
    "    return weighted_std\n",
    "\n",
    "\n",
    "# Create mini (discretized) population\n",
    "df_mini_pop_01 = create_mini_population(normal_distribution, lowest_height_mini_pop_01, highest_height_mini_pop_01, \n",
    "                                        approx_num_bars_mini_pop_01, approx_total_count_mini_pop_01, mean_height_mini_pop_01, std_height_mini_pop_01)\n",
    "\n",
    "# Display mini population\n",
    "display(df_mini_pop_01)\n",
    "\n",
    "# Plot mini population\n",
    "fig, ax = plt.subplots(figsize=(4, 4))\n",
    "plot_mini_population(df_mini_pop_01, ax, \"Population 1\")\n",
    "ax.set_title('Mini Population of Human Heights')\n",
    "ax.set_xlabel('Height (inches)')\n",
    "ax.set_ylabel('Count')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary\n",
    "mean_mini_pop_01 = calculate_weighted_mean(df_mini_pop_01['Height'], df_mini_pop_01['Count'])\n",
    "std_mini_pop_01 = calculate_weighted_std(df_mini_pop_01['Height'], df_mini_pop_01['Count'])\n",
    "\n",
    "print(f\"Unique elements: {df_mini_pop_01['Height'].unique()}\")\n",
    "print(f\"Total count of elements: {df_mini_pop_01['Count'].sum()}\")\n",
    "print(f\"Mean: {mean_mini_pop_01}\")\n",
    "print(f\"Std: {std_mini_pop_01:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1e32c0-dd00-44b0-84de-f293f56cd944",
   "metadata": {},
   "source": [
    "### Create mini population 02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131efdeb-9176-4da5-ba40-383ab8729d4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lowest_height_mini_pop_02= 75\n",
    "mean_height_mini_pop_02 = 90\n",
    "highest_height_mini_pop_02 = 105\n",
    "std_height_mini_pop_02 = 3\n",
    "num_bars_mini_pop_02 = 100\n",
    "approx_num_bars_mini_pop_02=9\n",
    "approx_total_count_mini_pop_02=30\n",
    "\n",
    "def plot_two_mini_pops(df1, df2):\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    \n",
    "    # Plot the first mini population\n",
    "    plot_mini_population(df1, ax, \"Population 1\")\n",
    "    \n",
    "    # Plot the second mini population\n",
    "    plot_mini_population(df2, ax, \"Population 2\")\n",
    "    \n",
    "    ax.set_title('Mini Populations of Human Heights (Not realistic)')\n",
    "    ax.set_xlabel('Height (inches)')\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "# Create mini (discretized) population\n",
    "df_mini_pop_02 = create_mini_population(normal_distribution, lowest_height_mini_pop_02, highest_height_mini_pop_02, \n",
    "                                        approx_num_bars_mini_pop_02, approx_total_count_mini_pop_02, mean_height_mini_pop_02, std_height_mini_pop_02)\n",
    "\n",
    "# Summary\n",
    "# Mini pop 01\n",
    "mean_mini_pop_01 = calculate_weighted_mean(df_mini_pop_01['Height'], df_mini_pop_01['Count'])\n",
    "std_mini_pop_01 = calculate_weighted_std(df_mini_pop_01['Height'], df_mini_pop_01['Count'])\n",
    "\n",
    "print('Mini pop 01')\n",
    "display(df_mini_pop_01)\n",
    "#print(f\"Unique elements: {df_mini_pop_01['Height'].unique()}\")\n",
    "print(f\"Total count of elements: {df_mini_pop_01['Count'].sum()}\")\n",
    "print(f\"Mean: {mean_mini_pop_01}\")\n",
    "print(f\"Std: {std_mini_pop_01:.2f}\")\n",
    "\n",
    "print('')\n",
    "\n",
    "# Mini pop 02\n",
    "mean_mini_pop_02 = calculate_weighted_mean(df_mini_pop_02['Height'], df_mini_pop_02['Count'])\n",
    "std_mini_pop_02 = calculate_weighted_std(df_mini_pop_02['Height'], df_mini_pop_02['Count'])\n",
    "\n",
    "print('Mini pop 02')\n",
    "display(df_mini_pop_02)\n",
    "#print(f\"Unique elements: {df_mini_pop_02['Height'].unique()}\")\n",
    "print(f\"Total count of elements: {df_mini_pop_02['Count'].sum()}\")\n",
    "print(f\"Mean: {mean_mini_pop_02}\")\n",
    "print(f\"Std: {std_mini_pop_02:.2f}\")\n",
    "\n",
    "# Plot mini population\n",
    "plot_two_mini_pops(df_mini_pop_01, df_mini_pop_02)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c5c227-2841-41c8-9d4b-535d15117e25",
   "metadata": {
    "tags": []
   },
   "source": [
    "### SDSM of the mini population 01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbb61e5-d8d9-4257-8943-f11156a44067",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_size_mini_pop_01 = 5\n",
    "repetitions_montecarlo = 100\n",
    "\n",
    "def calculate_SDSM_exhaustive(df, sample_size):\n",
    "    unique_heights = df['Height'].values\n",
    "    unique_probabilities = df['Probability'].values\n",
    "    # Generate all possible combinations\n",
    "    all_combs = list(product(unique_heights, repeat=sample_size))\n",
    "    # Calculate their probabilities and mean\n",
    "    probabilities = []\n",
    "    means = []\n",
    "    for comb in all_combs:\n",
    "        prob = np.prod([unique_probabilities[np.where(unique_heights == x)[0][0]] for x in comb])\n",
    "        mean = np.mean(comb)\n",
    "        probabilities.append(prob)\n",
    "        means.append(mean)\n",
    "    # Create df_combinations\n",
    "    df_combinations = pd.DataFrame({\n",
    "        'Combination': all_combs,\n",
    "        'Mean': means,\n",
    "        'Probability': probabilities\n",
    "    })\n",
    "    # Round the 'Mean' column to 2 decimal places\n",
    "    # df_combinations['Mean'] = df_combinations['Mean'].round(2)\n",
    "    # Calculate empirical SE\n",
    "    empirical_SE = np.sqrt(np.sum([p * m**2 for p, m in zip(probabilities, means)]) - np.sum([p * m for p, m in zip(probabilities, means)])**2)\n",
    "    return df_combinations, empirical_SE\n",
    "\n",
    "# To correct numerical approximations after the mean is calculated\n",
    "# def rectify_df_combinations(df_combinations):\n",
    "#     df_combinations_copy = df_combinations.copy(deep=True)\n",
    "#     # Initialize the new Mean_rectified column with zeros\n",
    "#     df_combinations_copy['Mean_rectified'] = 0.0\n",
    "#     # Calculate the new Mean_rectified values\n",
    "#     for idx, row in df_combinations_copy.iterrows():\n",
    "#         current_mean = row['Mean']\n",
    "#         current_mean_ceiled = np.round(np.ceil(current_mean * 100) / 100, 2)\n",
    "#         is_within_0_01 = np.abs(df_combinations_copy['Mean'].apply(lambda x: np.round(np.ceil(x * 100) / 100, 2)) - current_mean_ceiled) < 0.011\n",
    "#         is_greater = df_combinations_copy['Mean'].apply(lambda x: np.round(np.ceil(x * 100) / 100, 2)) > current_mean_ceiled\n",
    "#         mean_adjusted = (is_within_0_01 & is_greater).any()\n",
    "#         df_combinations_copy.at[idx, 'Mean_rectified'] = current_mean_ceiled + 0.01 if mean_adjusted else current_mean_ceiled\n",
    "#     probabilities = df_combinations_copy['Probability'].values\n",
    "#     mean_rectified_values = df_combinations_copy['Mean_rectified'].values\n",
    "#     weighted_mean = np.sum(probabilities * mean_rectified_values)\n",
    "#     weighted_var = np.sum(probabilities * (mean_rectified_values - weighted_mean)**2)\n",
    "#     empirical_SE = np.sqrt(weighted_var)\n",
    "#     return df_combinations_copy, empirical_SE\n",
    "def rectify_df_combinations(df_combinations):\n",
    "    df_combinations_copy = df_combinations.copy(deep=True)\n",
    "    # Initialize the new Mean_rectified column with zeros\n",
    "    df_combinations_copy['Mean_rectified'] = 0.0\n",
    "    # Calculate the new Mean_rectified values\n",
    "    for idx, row in df_combinations_copy.iterrows():\n",
    "        current_mean = row['Mean']\n",
    "        current_mean_ceiled = np.round(np.ceil(current_mean * 100) / 100, 2)\n",
    "        is_within_0_01 = np.abs(df_combinations_copy['Mean'].apply(lambda x: np.round(np.ceil(x * 100) / 100, 2)) - current_mean_ceiled) < 0.011\n",
    "        is_greater = df_combinations_copy['Mean'].apply(lambda x: np.round(np.ceil(x * 100) / 100, 2)) > current_mean_ceiled\n",
    "        mean_adjusted = (is_within_0_01 & is_greater).any()\n",
    "        df_combinations_copy.at[idx, 'Mean_rectified'] = np.ceil(current_mean_ceiled) if mean_adjusted else current_mean_ceiled\n",
    "    # Check if 'Probability' column exists in df_combinations (exhaustive method)\n",
    "    if 'Probability' in df_combinations_copy.columns: \n",
    "        probabilities = df_combinations_copy['Probability'].values\n",
    "        means = df_combinations_copy['Mean_rectified'].values\n",
    "        empirical_SE = np.sqrt(np.sum([p * m**2 for p, m in zip(probabilities, means)]) - np.sum([p * m for p, m in zip(probabilities, means)])**2)\n",
    "    else: # (monte carlo method)\n",
    "        empirical_SE = df_combinations_copy['Mean_rectified'].std()\n",
    "    return df_combinations_copy, empirical_SE\n",
    "\n",
    "# Calculate SDSM by the Monte Carlo method (repeated random sampling)\n",
    "def calculate_SDSM_montecarlo(df, sample_size, title, num_samples):\n",
    "    # Extract the height and probability data\n",
    "    heights = df['Height'].values\n",
    "    probabilities = df['Probability'].values\n",
    "    # Initialize an array to store the sample means\n",
    "    sample_means = np.zeros(num_samples)\n",
    "    # Generate sample means according to the given probabilities\n",
    "    for i in range(num_samples):\n",
    "        random_sample = np.random.choice(heights, size=sample_size, p=probabilities)\n",
    "        sample_means[i] = np.mean(random_sample)\n",
    "    # Calculate the empirical Standard Error (SE)\n",
    "    empirical_SE = np.std(sample_means, ddof=1)\n",
    "    # Create a df with the sample means\n",
    "    df_combinations = pd.DataFrame({'Mean': sample_means})\n",
    "    return df_combinations, empirical_SE \n",
    "\n",
    "# def calculate_SDSM_montecarlo(df, sample_size, title, num_samples):\n",
    "#     # Extract the height and probability data\n",
    "#     heights = df['Height'].values\n",
    "#     probabilities = df['Probability'].values\n",
    "    \n",
    "#     # Initialize an array to store the sample means\n",
    "#     sample_means = np.zeros(num_samples)\n",
    "    \n",
    "#     # Generate sample means according to the given probabilities\n",
    "#     for i in range(num_samples):\n",
    "#         random_sample = np.random.choice(heights, size=sample_size, p=probabilities)\n",
    "#         sample_means[i] = np.mean(random_sample)\n",
    "    \n",
    "#     # Create a temporary DataFrame with the sample means\n",
    "#     temp_df = pd.DataFrame({'Mean': sample_means})\n",
    "    \n",
    "#     # Group by the same means and calculate probabilities\n",
    "#     total_samples = num_samples\n",
    "#     probabilities = temp_df['Mean'].value_counts(normalize=True).reset_index()\n",
    "#     probabilities.columns = ['Mean', 'Probability']\n",
    "    \n",
    "#     # Calculate the empirical Standard Error (SE)\n",
    "#     empirical_SE = np.std(sample_means, ddof=1)\n",
    "    \n",
    "#     return probabilities, empirical_SE\n",
    "\n",
    "# Calculate SDSM by the Monte Carlo method using parallel computing\n",
    "def calculate_SDSM_montecarlo_torch(df, sample_size, repetitions):\n",
    "    heights = torch.tensor(df['Height'].values, dtype=torch.float)\n",
    "    probabilities = torch.tensor(df['Probability'].values, dtype=torch.float)\n",
    "    dist = torch.distributions.Categorical(probs=probabilities)\n",
    "    random_indices = dist.sample((repetitions, sample_size))\n",
    "    random_samples = torch.index_select(heights, 0, random_indices.flatten()).view(repetitions, sample_size)\n",
    "    sample_means = torch.mean(random_samples, dim=1)\n",
    "    empirical_SE = np.std(sample_means.cpu().numpy(), ddof=1)\n",
    "    # Create a df with the sample means\n",
    "    df_combinations = pd.DataFrame({'Mean': sample_means})\n",
    "    return df_combinations, empirical_SE\n",
    "\n",
    "# def calculate_SDSM_montecarlo_torch(df, sample_size, repetitions):\n",
    "#     heights = torch.tensor(df['Height'].values, dtype=torch.float)\n",
    "#     probabilities = torch.tensor(df['Probability'].values, dtype=torch.float)\n",
    "#     dist = torch.distributions.Categorical(probs=probabilities)\n",
    "#     random_indices = dist.sample((repetitions, sample_size))\n",
    "#     random_samples = torch.index_select(heights, 0, random_indices.flatten()).view(repetitions, sample_size)\n",
    "#     sample_means = torch.mean(random_samples, dim=1)\n",
    "#     empirical_SE = np.std(sample_means.cpu().numpy(), ddof=1)\n",
    "    \n",
    "#     # Create a tensor of repeated probabilities\n",
    "#     repeated_probabilities = probabilities.repeat(repetitions)\n",
    "    \n",
    "#     # Create a DataFrame with 'Mean' and 'Probability' columns\n",
    "#     df_combinations = pd.DataFrame({\n",
    "#         'Mean': sample_means.cpu().numpy(),\n",
    "#         'Probability': repeated_probabilities.cpu().numpy()\n",
    "#     })\n",
    "    \n",
    "#     return df_combinations, empirical_SE\n",
    "\n",
    "def plot_sdsm(df_combinations, sample_size, title, column_name='Mean'):\n",
    "    # Group by the mean and count the occurrences\n",
    "    mean_counts = df_combinations.groupby(column_name).size().reset_index(name='Counts')\n",
    "    # Plotting\n",
    "    fig, ax = plt.subplots(figsize=(3, 2.5))\n",
    "    ax.scatter(mean_counts[column_name], mean_counts['Counts'], alpha=0.7, s=50)\n",
    "    ax.plot(mean_counts[column_name], mean_counts['Counts'], color='blue', linewidth=0.8)\n",
    "    for _, row in mean_counts.iterrows():\n",
    "        ax.plot([row[column_name], row[column_name]], [0, row['Counts']], linestyle='--', color='grey', linewidth=0.5)\n",
    "    ax.xaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(column_name)\n",
    "    ax.set_ylabel('Count')\n",
    "    if len(mean_counts[column_name]) > 30:\n",
    "        ax.set_xticks(np.linspace(mean_counts[column_name].min(), mean_counts[column_name].max(), 10))\n",
    "    else:\n",
    "        ax.set_xticks(mean_counts[column_name].values)\n",
    "    ax.set_ylim(0,)\n",
    "    if len(mean_counts[column_name]) > 4:\n",
    "        ax.tick_params(axis='x', rotation=90)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def generate_mean_summary_df(df_combinations, column_name):\n",
    "    mean_summary = df_combinations.groupby(column_name).size().reset_index(name='Total_count')\n",
    "    mean_summary['Probability'] = mean_summary['Total_count'] / mean_summary['Total_count'].sum()\n",
    "    mean_summary['Probability'] = mean_summary['Probability'].round(4)\n",
    "    return mean_summary\n",
    "\n",
    "def compare_empirical_estimated_SE(mean_pop, empirical_SE, pop_std, sample_size):\n",
    "    theoretical_SE = pop_std / np.sqrt(sample_size)\n",
    "    print(f\"Mini pop mean: {mean_pop:.2f}\")\n",
    "    print(f\"Mini pop std: {pop_std:.2f}\")\n",
    "    print(f\"SDSM sample size: {sample_size}\")\n",
    "    print(f\"SDSM empirical SE: {empirical_SE:.2f}\")\n",
    "    print(f\"SDSM theoretical SE (from mini pop std): {theoretical_SE:.2f}\")\n",
    "    print(f\"SDSM empirical SE/theoretical SE: {(empirical_SE/theoretical_SE) * 100:.2f}%\")\n",
    "\n",
    "# Calculate SDSM by the exhaustive method (create all possible score combinations and calculate their means of mini pop 01 )    \n",
    "print('SDSM mini pop 01 estimated by the exhaustive method:')\n",
    "df_sdsm_mini_pop_01_exhaustive_temp, _ = calculate_SDSM_exhaustive(df_mini_pop_01, sample_size_mini_pop_01)\n",
    "df_sdsm_mini_pop_01_exhaustive, SE_mini_pop_01_exhaustive = rectify_df_combinations(df_sdsm_mini_pop_01_exhaustive_temp)\n",
    "display(df_sdsm_mini_pop_01_exhaustive)\n",
    "plot_sdsm(df_sdsm_mini_pop_01_exhaustive, sample_size_mini_pop_01, f\"SDSM exhaustive (n = {sample_size_mini_pop_01})\", column_name='Mean_rectified')\n",
    "compare_empirical_estimated_SE(mean_mini_pop_01, SE_mini_pop_01_exhaustive, std_mini_pop_01, sample_size_mini_pop_01)\n",
    "display(generate_mean_summary_df(df_sdsm_mini_pop_01_exhaustive, \"Mean_rectified\"))\n",
    "\n",
    "print('\\nSDSM mini pop 01 estimated by the Monte Carlo method:')\n",
    "df_sdsm_mini_pop_01_montecarlo_temp, SE_mini_pop_01_montecarlo_temp = calculate_SDSM_montecarlo(df_mini_pop_01, sample_size_mini_pop_01, \"title\", repetitions_montecarlo)\n",
    "df_sdsm_mini_pop_01_montecarlo, SE_mini_pop_01_montecarlo = rectify_df_combinations(df_sdsm_mini_pop_01_montecarlo_temp)\n",
    "display(df_sdsm_mini_pop_01_montecarlo)\n",
    "plot_sdsm(df_sdsm_mini_pop_01_montecarlo, sample_size_mini_pop_01, f\"SDSM montecarlo (n = {sample_size_mini_pop_01})\", column_name='Mean_rectified')\n",
    "compare_empirical_estimated_SE(mean_mini_pop_01, SE_mini_pop_01_montecarlo, std_mini_pop_01, sample_size_mini_pop_01)\n",
    "display(generate_mean_summary_df(df_sdsm_mini_pop_01_montecarlo, \"Mean_rectified\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dea88be-0eb9-46fd-a9fa-af5b98a27ace",
   "metadata": {},
   "source": [
    "### SDSM of the mini population 02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb278a8-57ff-4067-96cf-edf2e6e20c2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_size_mini_pop_02 = 5\n",
    "\n",
    "# Calculate SDSM by the exhaustive method (create all possible score combinations and calculate their means of mini pop 02 )    \n",
    "print('SDSM mini pop 02 estimated by the exhaustive method:')\n",
    "df_sdsm_mini_pop_02_exhaustive_temp, _ = calculate_SDSM_exhaustive(df_mini_pop_02, sample_size_mini_pop_02)\n",
    "df_sdsm_mini_pop_02_exhaustive, SE_mini_pop_02_exhaustive = rectify_df_combinations(df_sdsm_mini_pop_02_exhaustive_temp)\n",
    "display(df_sdsm_mini_pop_02_exhaustive)\n",
    "plot_sdsm(df_sdsm_mini_pop_02_exhaustive, sample_size_mini_pop_02, f\"SDSM exhaustive (n = {sample_size_mini_pop_02})\", column_name='Mean_rectified')\n",
    "print(df_sdsm_mini_pop_02_exhaustive['Mean_rectified'].unique())\n",
    "compare_empirical_estimated_SE(mean_mini_pop_02, SE_mini_pop_02_exhaustive, std_mini_pop_02, sample_size_mini_pop_02)\n",
    "display(generate_mean_summary_df(df_sdsm_mini_pop_02_exhaustive, \"Mean_rectified\"))\n",
    "\n",
    "# print('\\nSDSM mini pop 02 estimated by the Monte Carlo method:')\n",
    "# df_sdsm_mini_pop_02_montecarlo_temp, SE_mini_pop_02_montecarlo_temp = calculate_SDSM_montecarlo(df_mini_pop_02, sample_size_mini_pop_02, \"title\", repetitions_montecarlo)\n",
    "# df_sdsm_mini_pop_02_montecarlo, SE_mini_pop_02_montecarlo = rectify_df_combinations(df_sdsm_mini_pop_02_montecarlo_temp)\n",
    "# display(df_sdsm_mini_pop_02_montecarlo)\n",
    "# plot_sdsm(df_sdsm_mini_pop_02_montecarlo, sample_size_mini_pop_02, f\"SDSM montecarlo (n = {sample_size_mini_pop_02})\", column_name='Mean_rectified')\n",
    "# compare_empirical_estimated_SE(mean_mini_pop_02, SE_mini_pop_02_montecarlo, std_mini_pop_02, sample_size_mini_pop_02)\n",
    "# display(generate_mean_summary_df(df_sdsm_mini_pop_02_montecarlo, \"Mean_rectified\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3ce670-7d97-4bf6-8b8e-a64ef14f393f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rectify_df_combinations(df_combinations):\n",
    "    df_combinations_copy = df_combinations.copy(deep=True)\n",
    "    # Initialize the new Mean_rectified column with zeros\n",
    "    df_combinations_copy['Mean_rectified'] = 0.0\n",
    "    # Calculate the new Mean_rectified values\n",
    "    for idx, row in df_combinations_copy.iterrows():\n",
    "        current_mean = row['Mean']\n",
    "        current_mean_ceiled = np.round(np.ceil(current_mean * 100) / 100, 2)\n",
    "        is_within_0_01 = np.abs(df_combinations_copy['Mean'].apply(lambda x: np.round(np.ceil(x * 100) / 100, 2)) - current_mean_ceiled) < 0.011\n",
    "        is_greater = df_combinations_copy['Mean'].apply(lambda x: np.round(np.ceil(x * 100) / 100, 2)) > current_mean_ceiled\n",
    "        mean_adjusted = (is_within_0_01 & is_greater).any()\n",
    "        df_combinations_copy.at[idx, 'Mean_rectified'] = np.ceil(current_mean_ceiled) if mean_adjusted else current_mean_ceiled\n",
    "    # Check if 'Probability' column exists in df_combinations (exhaustive method)\n",
    "    if 'Probability' in df_combinations_copy.columns: \n",
    "        probabilities = df_combinations_copy['Probability'].values\n",
    "        means = df_combinations_copy['Mean_rectified'].values\n",
    "        empirical_SE = np.sqrt(np.sum([p * m**2 for p, m in zip(probabilities, means)]) - np.sum([p * m for p, m in zip(probabilities, means)])**2)\n",
    "    else: # (monte carlo method)\n",
    "        empirical_SE = df_combinations_copy['Mean_rectified'].std()\n",
    "    return df_combinations_copy, empirical_SE\n",
    "\n",
    "\n",
    "df = df_sdsm_mini_pop_02_exhaustive.copy(deep=True)\n",
    "display(generate_mean_summary_df(df, \"Mean\"))\n",
    "df_rect = rectify_df_combinations(df)\n",
    "display(df_rect)\n",
    "#display(generate_mean_summary_df(df_rect, \"Mean_rectified\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0415bc2c-556b-422f-833d-6c7476bce33a",
   "metadata": {},
   "source": [
    "### Get samples of mini population 01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3dd5831-a0e5-4bd6-8532-89f99491f415",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_sample_mini_pop_01 = 10\n",
    "alpha_mini_pop_01 = 0.05\n",
    "\n",
    "def generate_random_sample(df_mini_pop, sample_size):\n",
    "    normalized_probabilities = df_mini_pop['Probability'] / df_mini_pop['Probability'].sum()\n",
    "    sampled_means = np.random.choice(df_mini_pop['Height'], size=sample_size, p=normalized_probabilities)\n",
    "    unique_values, counts = np.unique(sampled_means, return_counts=True)\n",
    "    sampled_df = pd.DataFrame({'Height': unique_values, 'Count': counts})\n",
    "    return sampled_df\n",
    "\n",
    "def calculate_sample_z_score(sample_mean, population_mean, population_std):\n",
    "    sample_z_score = (sample_mean - population_mean) / population_std\n",
    "    return sample_z_score\n",
    "\n",
    "def plot_z_distribution(sample_z_score, alpha, title):\n",
    "    x = np.linspace(-4, 4, 400)  # Range of z-scores\n",
    "    plt.figure(figsize=(5, 3))\n",
    "    plt.plot(x, stats.norm.pdf(x), color='blue', label='Z-Distribution')\n",
    "    x_fill = np.linspace(-4, -abs(stats.norm.ppf(alpha/2)), 100)  # Area to shade above alpha/2 on the left tail\n",
    "    plt.fill_between(x_fill, stats.norm.pdf(x_fill), color='blue', alpha=0.2)\n",
    "    x_fill = np.linspace(abs(stats.norm.ppf(alpha/2)), 4, 100)  # Area to shade above alpha/2 on the right tail\n",
    "    plt.fill_between(x_fill, stats.norm.pdf(x_fill), color='blue', alpha=0.2)\n",
    "    plt.scatter(sample_z_score, 0, color='red', label=f'Sample Z-Score', zorder=5)\n",
    "    # Add texts for p < alpha and p > alpha\n",
    "    plt.text(-3.5, 0.02, r'$p < \\alpha/2$', fontsize=12, ha='center', color='black')\n",
    "    plt.text(3.5, 0.02, r'$p < \\alpha/2$', fontsize=12, ha='center', color='black')\n",
    "    plt.xlabel('Z-Score')\n",
    "    plt.ylabel('Density')\n",
    "    plt.title(title)\n",
    "    alpha_x = abs(stats.norm.ppf(alpha/2))\n",
    "    alpha_patch = mpatches.Patch(color='blue', alpha=0.2, label=f'$\\\\alpha$/2 ({alpha * 100}%): $\\\\pm${alpha_x:.2f}')\n",
    "    plt.legend(handles=[alpha_patch], loc='upper right', bbox_to_anchor=(1.5, 1))\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "def decision_z_distribution(mean_pop, mean_sample, sample_z_score, sample_size, alpha):\n",
    "    df = sample_size - 1\n",
    "    # Calculate the two-tailed p-value\n",
    "    p_value = 2 * (1 - norm.cdf(abs(sample_z_score)))\n",
    "    print(f\"Decision: Because z({df}) = {sample_z_score:.4f}, p = {p_value:.4f} < {alpha} (two-tailed z-test),\", end=\" \")\n",
    "    if p_value < alpha:\n",
    "         print(f\"the null hypothesis can be rejected.\\nThe sample mean (= {mean_sample}) is significantly different from the population mean (= {mean_pop}).\")\n",
    "    else:\n",
    "        print(f\"the null hypothesis can NOT be rejected.\\nThe sample mean ( ={mean_sample}) is NOT significantly different from the population mean (= {mean_pop}).\")\n",
    "        \n",
    "# Random sample following the normal probabilites\n",
    "df_random_sample_mini_pop_01 = generate_random_sample(df_mini_pop_01, size_sample_mini_pop_01)\n",
    "mean_random_sample_mini_pop_01 = calculate_weighted_mean(df_random_sample_mini_pop_01['Height'], df_random_sample_mini_pop_01['Count']).round(4)\n",
    "std_random_sample_mini_pop_01 = calculate_weighted_std(df_random_sample_mini_pop_01['Height'], df_random_sample_mini_pop_01['Count']).round(4)\n",
    "z_score_random_sample_mini_pop_01 = calculate_sample_z_score(mean_random_sample_mini_pop_01, mean_mini_pop_01, std_mini_pop_01)\n",
    "print(\"Mini pop 01\\n\")\n",
    "print(f\"Mean: {mean_mini_pop_01}\")\n",
    "print(f\"Std: {std_mini_pop_01:.2f}\")\n",
    "print(\"\\nRandom sample \")\n",
    "display(df_random_sample_mini_pop_01)\n",
    "print(f\"Sample size: {df_random_sample_mini_pop_01['Count'].sum()}\")\n",
    "print(f\"Mean: {mean_random_sample_mini_pop_01}\")\n",
    "print(f\"Std: {std_random_sample_mini_pop_01:.2f}\")\n",
    "print(f\"Z-score: {z_score_random_sample_mini_pop_01:.2f}\")\n",
    "plot_z_distribution(z_score_random_sample_mini_pop_01, alpha_mini_pop_01, 'Z-Distribution mini pop 01')\n",
    "decision_z_distribution(mean_mini_pop_01, mean_random_sample_mini_pop_01, z_score_random_sample_mini_pop_01, size_sample_mini_pop_01, alpha_mini_pop_01)\n",
    "          \n",
    "# Extreme sample\n",
    "extreme_sample_mini_pop_01_dict = {'Height': [df_mini_pop_01['Height'].iloc[-1]], 'Count': [size_sample_mini_pop_01]}\n",
    "df_extreme_sample_mini_pop_01 = pd.DataFrame(extreme_sample_mini_pop_01_dict)\n",
    "mean_extreme_sample_mini_pop_01 = calculate_weighted_mean(df_extreme_sample_mini_pop_01['Height'], df_extreme_sample_mini_pop_01['Count']).round(4)\n",
    "std_extreme_sample_mini_pop_01 = calculate_weighted_std(df_extreme_sample_mini_pop_01['Height'], df_extreme_sample_mini_pop_01['Count']).round(4)\n",
    "z_score_extreme_sample_mini_pop_01 = calculate_sample_z_score(mean_extreme_sample_mini_pop_01, mean_mini_pop_01, std_mini_pop_01)\n",
    "print(\"\\nExtreme sample \")\n",
    "display(df_extreme_sample_mini_pop_01)\n",
    "print(f\"Sample size: {df_extreme_sample_mini_pop_01['Count'].sum()}\")\n",
    "print(f\"Mean: {mean_extreme_sample_mini_pop_01}\")\n",
    "print(f\"Std: {std_extreme_sample_mini_pop_01:.2f}\")\n",
    "print(f\"Z-score: {z_score_extreme_sample_mini_pop_01:.2f}\")\n",
    "plot_z_distribution(z_score_extreme_sample_mini_pop_01, alpha_mini_pop_01, 'Z-Distribution mini pop 01')\n",
    "decision_z_distribution(mean_mini_pop_01, mean_extreme_sample_mini_pop_01, z_score_extreme_sample_mini_pop_01, size_sample_mini_pop_01, alpha_mini_pop_01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3cd639-bec5-4d7f-a071-afd58e6c276e",
   "metadata": {},
   "source": [
    "### Get samples of mini population 02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100ff8c3-9726-421d-9646-d9c7a890a202",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "size_sample_mini_pop_02 = 10\n",
    "alpha_mini_pop_02 = 0.05\n",
    "\n",
    "# Random sample following the normal probabilites\n",
    "df_random_sample_mini_pop_02 = generate_random_sample(df_mini_pop_02, size_sample_mini_pop_02)\n",
    "mean_random_sample_mini_pop_02 = calculate_weighted_mean(df_random_sample_mini_pop_02['Height'], df_random_sample_mini_pop_02['Count']).round(4)\n",
    "std_random_sample_mini_pop_02 = calculate_weighted_std(df_random_sample_mini_pop_02['Height'], df_random_sample_mini_pop_02['Count']).round(4)\n",
    "z_score_random_sample_mini_pop_02 = calculate_sample_z_score(mean_random_sample_mini_pop_02, mean_mini_pop_02, std_mini_pop_02)\n",
    "print(\"Mini pop 02\\n\")\n",
    "print(f\"Mean: {mean_mini_pop_02}\")\n",
    "print(f\"Std: {std_mini_pop_02:.2f}\")\n",
    "print(\"\\nRandom sample \")\n",
    "display(df_random_sample_mini_pop_02)\n",
    "print(f\"Sample size: {df_random_sample_mini_pop_02['Count'].sum()}\")\n",
    "print(f\"Mean: {mean_random_sample_mini_pop_02}\")\n",
    "print(f\"Std: {std_random_sample_mini_pop_02:.2f}\")\n",
    "print(f\"Z-score: {z_score_random_sample_mini_pop_02:.2f}\")\n",
    "plot_z_distribution(z_score_random_sample_mini_pop_02, alpha_mini_pop_02, 'Z-Distribution mini pop 02')\n",
    "decision_z_distribution(mean_mini_pop_02, mean_random_sample_mini_pop_02, z_score_random_sample_mini_pop_02, size_sample_mini_pop_02, alpha_mini_pop_02)\n",
    "\n",
    "# Extreme sample\n",
    "extreme_sample_mini_pop_02_dict = {'Height': [df_mini_pop_02['Height'].iloc[-1]], 'Count': [size_sample_mini_pop_02]}\n",
    "df_extreme_sample_mini_pop_02 = pd.DataFrame(extreme_sample_mini_pop_02_dict)\n",
    "mean_extreme_sample_mini_pop_02 = calculate_weighted_mean(df_extreme_sample_mini_pop_02['Height'], df_extreme_sample_mini_pop_02['Count']).round(4)\n",
    "std_extreme_sample_mini_pop_02 = calculate_weighted_std(df_extreme_sample_mini_pop_02['Height'], df_extreme_sample_mini_pop_02['Count']).round(4)\n",
    "z_score_extreme_sample_mini_pop_02 = calculate_sample_z_score(mean_extreme_sample_mini_pop_02, mean_mini_pop_02, std_mini_pop_02)\n",
    "print(\"\\nExtreme sample \")\n",
    "display(df_extreme_sample_mini_pop_02)\n",
    "print(f\"Sample size: {df_extreme_sample_mini_pop_02['Count'].sum()}\")\n",
    "print(f\"Mean: {mean_extreme_sample_mini_pop_02}\")\n",
    "print(f\"Std: {std_extreme_sample_mini_pop_02:.2f}\")\n",
    "print(f\"Z-score: {z_score_extreme_sample_mini_pop_02:.2f}\")\n",
    "plot_z_distribution(z_score_extreme_sample_mini_pop_02, alpha_mini_pop_02, 'Z-Distribution mini pop 02')\n",
    "decision_z_distribution(mean_mini_pop_02, mean_extreme_sample_mini_pop_02, z_score_extreme_sample_mini_pop_02, size_sample_mini_pop_02, alpha_mini_pop_02)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f728100-bb35-483e-9fd7-c117cac5f4cd",
   "metadata": {},
   "source": [
    "### One sample t-test\n",
    "We pretend that we don't know the population std. The SDMS is built using the sample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76489520-ab91-4884-aced-4e1d81e4b175",
   "metadata": {},
   "source": [
    "#### SDMS t-test sample mini pop 01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711ce2fd-5a25-4aef-9d7d-509b8790e488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import numpy as np\n",
    "# from itertools import product\n",
    "# import pandas as pd\n",
    "# import time\n",
    "\n",
    "# def calculate_SE_efficiently(df, sample_size):\n",
    "#     unique_scores = df['Height'].unique()\n",
    "#     all_combs = np.array(list(product(unique_scores, repeat=sample_size)), dtype=np.float64)\n",
    "#     means = np.mean(all_combs, axis=1)\n",
    "#     SE = np.std(means)\n",
    "#     return SE\n",
    "\n",
    "# def calculate_SE_efficiently_torch(df, sample_size):\n",
    "#     # Convert unique scores to a PyTorch tensor and move it to GPU if available\n",
    "#     unique_scores = torch.tensor(df['Height'].unique(), dtype=torch.float64).cuda() if torch.cuda.is_available() else torch.tensor(df['Height'].unique(), dtype=torch.float64)\n",
    "#     # Create all possible combinations and move them to GPU if available\n",
    "#     all_combs = torch.tensor(list(product(unique_scores.cpu().numpy(), repeat=sample_size)), dtype=torch.float64).cuda() if torch.cuda.is_available() else torch.tensor(list(product(unique_scores.cpu().numpy(), repeat=sample_size)), dtype=torch.float64)\n",
    "#     # Calculate the mean along axis 1\n",
    "#     means = torch.mean(all_combs, axis=1)\n",
    "#     # Calculate the standard deviation of the means to get SE\n",
    "#     SE = torch.std(means)\n",
    "#     return SE.item()  # Convert the result back to a Python native type\n",
    "\n",
    "# # Test example\n",
    "\n",
    "\n",
    "# # Create a sample DataFrame\n",
    "# df = pd.DataFrame({'Height': [170, 180, 190, 200, 210]})\n",
    "# sample_size = 10\n",
    "\n",
    "# print(f\"Sample size: {sample_size}\")\n",
    "# # CPU\n",
    "# start_time = time.time()\n",
    "# SE = calculate_SE_efficiently(df, sample_size)\n",
    "# end_time = time.time()\n",
    "# print(\"Time taken using NumPy (CPU):\", end_time - start_time)\n",
    "# print(f\"The calculated SE is: {SE}\")\n",
    "\n",
    "# # GPU\n",
    "# start_time = time.time()\n",
    "# SE = calculate_SE_efficiently_torch(df, sample_size)\n",
    "# end_time = time.time()\n",
    "# print(\"Time taken using NumPy (GPU):\", end_time - start_time)\n",
    "# print(f\"The calculated SE is: {SE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea73ab22-2e13-4cf7-9414-f7625a517330",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Parameters for the original distribution\n",
    "original_mean = 10\n",
    "original_std_dev = 2\n",
    "\n",
    "# Number of random variables to sum up (sample size for each sample mean)\n",
    "n = 10\n",
    "\n",
    "# Number of times to compute the sample mean (number of samples)\n",
    "num_samples = 1000\n",
    "\n",
    "# Initialize an empty array to store sample means\n",
    "sample_means = np.zeros(num_samples)\n",
    "\n",
    "# Generate sample means\n",
    "for i in range(num_samples):\n",
    "    random_sample = np.random.normal(original_mean, original_std_dev, n)\n",
    "    sample_means[i] = np.mean(random_sample)\n",
    "\n",
    "# Theoretical mean and standard deviation for the sampling distribution of the sample mean\n",
    "theoretical_mean = original_mean\n",
    "theoretical_std_dev = original_std_dev / np.sqrt(n)\n",
    "\n",
    "# Plot the distribution of sample means\n",
    "sns.histplot(sample_means, bins=50, kde=True, label='Empirical DSM')\n",
    "\n",
    "# Overlay the theoretical normal distribution\n",
    "x = np.linspace(min(sample_means), max(sample_means), 100)\n",
    "y = norm.pdf(x, theoretical_mean, theoretical_std_dev)\n",
    "plt.plot(x, y, label='Theoretical DSM')\n",
    "plt.legend()\n",
    "\n",
    "# Display the empirical and theoretical standard deviations\n",
    "empirical_std_dev = np.std(sample_means)\n",
    "print(f'Empirical standard deviation of sample means: {empirical_std_dev}')\n",
    "print(f'Theoretical standard deviation of sample means: {theoretical_std_dev}')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feafd6e8-4f85-4706-b1e2-37754fe72fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Given population\n",
    "population = np.array([1, 2, 3, 4, 5])\n",
    "\n",
    "# Sample size\n",
    "n = 2\n",
    "\n",
    "# Calculate theoretical mean and standard deviation of the SDSM\n",
    "original_mean = np.mean(population)\n",
    "original_std_dev = np.std(population)\n",
    "theoretical_mean = original_mean\n",
    "theoretical_std_dev = original_std_dev / np.sqrt(n)\n",
    "\n",
    "# Generate all possible combinations of n elements from the population\n",
    "all_combinations = list(combinations(population, n))\n",
    "\n",
    "# Initialize an array to store the means of all combinations\n",
    "sample_means = np.zeros(len(all_combinations))\n",
    "\n",
    "# Calculate the means of all combinations\n",
    "for i, comb in enumerate(all_combinations):\n",
    "    sample_means[i] = np.mean(comb)\n",
    "\n",
    "# Plot the empirical SDSM with a blue color\n",
    "sns.histplot(sample_means, bins=50, kde=True, label='Empirical SDSM', color='blue')\n",
    "\n",
    "# Overlay the theoretical normal distribution with a red color\n",
    "x = np.linspace(min(sample_means), max(sample_means), 100)\n",
    "y = norm.pdf(x, theoretical_mean, theoretical_std_dev)\n",
    "plt.plot(x, y, label='Theoretical SDSM', color='red')\n",
    "plt.legend()\n",
    "\n",
    "# Display empirical and theoretical standard deviations\n",
    "empirical_std_dev = np.std(sample_means)\n",
    "print(f'Empirical standard deviation of sample means: {empirical_std_dev}')\n",
    "print(f'Theoretical standard deviation of sample means: {theoretical_std_dev}')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b64d60b-3d40-43db-b8c9-8a587417facd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "\n",
    "def calculate_SDSM_exhaustive(df, sample_size):\n",
    "    unique_heights = df['Height'].values\n",
    "    unique_probabilities = df['Probability'].values\n",
    "    # Generate all possible combinations\n",
    "    all_combs = list(product(unique_heights, repeat=sample_size))\n",
    "    # Calculate their probabilities and mean\n",
    "    probabilities = []\n",
    "    means = []\n",
    "    for comb in all_combs:\n",
    "        prob = np.prod([unique_probabilities[np.where(unique_heights == x)[0][0]] for x in comb])\n",
    "        mean = np.mean(comb)\n",
    "        probabilities.append(prob)\n",
    "        means.append(mean)\n",
    "    # Create df_combinations\n",
    "    df_combinations = pd.DataFrame({\n",
    "        'Combination': all_combs,\n",
    "        'Mean': means,\n",
    "        'Probability': probabilities\n",
    "    })\n",
    "    # Round the 'Mean' column to 2 decimal places\n",
    "    df_combinations['Mean'] = df_combinations['Mean'].round(2)\n",
    "    \n",
    "    # Calculate empirical SE\n",
    "    empirical_SE = np.sqrt(np.sum([p * m**2 for p, m in zip(probabilities, means)]) - np.sum([p * m for p, m in zip(probabilities, means)])**2)\n",
    "    \n",
    "    print(f\"Empirical SE: {empirical_SE:.2f}\")\n",
    "    \n",
    "    return df_combinations, empirical_SE\n",
    "\n",
    "# Sample dataframe\n",
    "df = pd.DataFrame({\n",
    "    'Height': [150, 160, 170],\n",
    "    'Probability': [0.2, 0.5, 0.3]\n",
    "})\n",
    "\n",
    "sample_size = 2\n",
    "df_combinations, empirical_SE = calculate_SDSM_exhaustive(df, sample_size)\n",
    "display(df_combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a5821e-ff00-481e-af97-32d03c1d0b0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(sum([0.166667, 0.666666, 0.166667]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0295dea0-baf3-46ef-895b-1da15ef2aeb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def group_sum_and_count(df):\n",
    "    rounded_mean = df['Mean'].apply(lambda x: round(x, 1))\n",
    "    df_temp = df.rename(columns={'Mean': 'Original_Mean'})\n",
    "    grouped_df = df_temp.groupby(rounded_mean).agg({'Probability': 'sum', 'Original_Mean': 'size'}).reset_index()\n",
    "    grouped_df.columns = ['Rounded_Mean', 'Count', 'Probability']\n",
    "    return grouped_df\n",
    "\n",
    "# Example DataFrame\n",
    "data = {'Mean': [1.21, 1.22, 1.23, 1.24, 2.45, 2.47, 3.12, 3.11],\n",
    "        'Probability': [0.1, 0.2, 0.3, 0.1, 0.5, 0.2, 0.4, 0.3]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "result_df = group_sum_and_count(df)\n",
    "print(result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c39d82a-aa81-471e-918c-607fe3c0f031",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
